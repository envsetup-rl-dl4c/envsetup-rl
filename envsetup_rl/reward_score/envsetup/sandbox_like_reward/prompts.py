#!/usr/bin/env python3
"""
Prompt utilities for LLM judge evaluation.
"""

from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field


class ScriptEvaluation(BaseModel):
    exit_code: int = Field(description="Expected exit code (0 for success, 1+ for failure)")
    issues_count: int = Field(description="Expected number of import issues (reportMissingImports from pyright)")
    repo_exploration: Optional[str] = Field(default=None, description="Results of running predefined exploration commands")


def load_dockerfile() -> str:
    """Load the Python Dockerfile content."""
    dockerfile_path = "dockerfiles/python.Dockerfile"
    try:
        with open(dockerfile_path, 'r') as f:
            return f.read()
    except FileNotFoundError:
        # Fallback to hardcoded content if file not found
        return """FROM ubuntu:22.04

# Set environment variables
ENV PYENV_ROOT="/root/.pyenv" \\
    PATH="/root/.pyenv/bin:/root/.pyenv/shims:/root/.pyenv/versions/3.12.0/bin:$PATH" \\
    DEBIAN_FRONTEND=noninteractive

# Install system dependencies and additional tools
RUN adduser --force-badname --system --no-create-home _apt \\
    && apt-get update -yqq \\
    && apt-get install -yqq \\
        python3 \\
        python3-pip \\
        curl \\
        wget \\
        tree \\
        zip \\
        unzip \\
        git \\
        software-properties-common \\
        build-essential \\
        zlib1g-dev \\
        libssl-dev \\
        libffi-dev \\
        libbz2-dev \\
        libreadline-dev \\
        libsqlite3-dev \\
        liblzma-dev \\
        libncurses5-dev \\
        libncursesw5-dev \\
        xz-utils \\
        tk-dev \\
        llvm \\
        libxml2-dev \\
        libxmlsec1-dev

# Install Pyenv and multiple Python versions
RUN git clone https://github.com/pyenv/pyenv.git $PYENV_ROOT \\
    && $PYENV_ROOT/bin/pyenv install 3.13.1 \\
    && $PYENV_ROOT/bin/pyenv install 3.12.0 \\
    && $PYENV_ROOT/bin/pyenv install 3.11.7 \\
    && $PYENV_ROOT/bin/pyenv install 3.10.13 \\
    && $PYENV_ROOT/bin/pyenv install 3.9.18 \\
    && $PYENV_ROOT/bin/pyenv install 3.8.18 \\
    && $PYENV_ROOT/bin/pyenv global 3.13.1 \\
    && $PYENV_ROOT/bin/pyenv rehash

# Install miniconda
ENV CONDA_DIR=/opt/conda
RUN wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh && \\
    /bin/bash ~/miniconda.sh -b -p /opt/conda

# Put conda in path so we can use conda activate
ENV PATH=$CONDA_DIR/bin:$PATH

# Install Poetry
RUN curl -sSL https://install.python-poetry.org | python3 - \\
    && ln -s /root/.local/bin/poetry /usr/bin/poetry

# Install uv
RUN pip install --no-cache-dir uv

# Install Pyright and other Python tools
RUN pip install --no-cache-dir pyright \\
    && pip install search-and-replace \\
    && pip install pipenv

# Install Node.js and jq
RUN curl -fsSL https://deb.nodesource.com/setup_20.x | bash - \\
    && apt-get install -y nodejs jq

# Remove lists
RUN rm -rf /var/lib/apt/lists/*

# Create and set working directory
RUN mkdir -p /data/project
WORKDIR /data/project

# Make conda always say yes to prompts
ENV CONDA_ALWAYS_YES=true

# Global pyenv versions:
# python3.13 points to 3.13.1, python3.12 points to 3.12.0, ...
RUN pyenv global 3.13.1 3.12.0 3.11.7 3.10.13 3.9.18 3.8.18

# Conda init bash
RUN conda init bash

# Set default shell to bash
CMD ["/bin/bash"]
"""


def load_build_script() -> str:
    """Load the Python build script content."""
    build_script_path = "evaluation/scripts/python_build.sh"
    try:
        with open(build_script_path, 'r') as f:
            return f.read()
    except FileNotFoundError:
        # Fallback to hardcoded content if file not found
        return """#!/bin/bash

set -e

# Create output directory
mkdir -p build_output
chmod -R 777 .
# initial contents
printf '{"pyright": {}}\n' > build_output/results.json

git config --global --add safe.directory /data/project

# Conda init
# >>> conda initialize >>>
# !! Contents within this block are managed by 'conda init' !!
__conda_setup="$('/opt/conda/bin/conda' 'shell.bash' 'hook' 2> /dev/null)"
if [ $? -eq 0 ]; then
    eval "$__conda_setup"
else
    if [ -f "/opt/conda/etc/profile.d/conda.sh" ]; then
        . "/opt/conda/etc/profile.d/conda.sh"
    else
        export PATH="/opt/conda/bin:$PATH"
    fi
fi
unset __conda_setup
# <<< conda initialize <<<

# If a bootstrap script exists, run it first
if [ -f "./bootstrap_script.sh" ]; then
  echo "Bootstrap script contents:"
  cat ./bootstrap_script.sh
  echo "Running bootstrap script..."
  source ./bootstrap_script.sh
fi

# Check that jq is installed
if ! command -v jq &> /dev/null; then
    echo "jq not found"
    exit 1
fi

# install pyright
python -m pip install --quiet pyright

# Print which Python is being used
echo "Using $(python --version) located at $(which python)"

# Run type checking with pyright
echo "Running type checks..."
if ! command -v pyright &> /dev/null; then
    echo "pyright not found"
    exit 1
fi

# Run pyright and capture its output regardless of exit code
python -m pyright /data/project --level error --outputjson > build_output/pyright_output.json || true

# Check if pyright output exists and is valid JSON
if [ ! -f build_output/pyright_output.json ]; then
    echo "Failed to get valid pyright output"
    exit 1
fi 

# Count only critical import issues (reportMissingImports)
issue_count=$(jq '[.generalDiagnostics[] | select(.rule == "reportMissingImports")] | length' \\
    build_output/pyright_output.json)

# Output results as JSON - exit code is 0 if pyright ran successfully, regardless of found issues
jq --arg issues "$issue_count" '. + {"issues_count": ($issues|tonumber)}' \\
    build_output/results.json > build_output/temp.json && \\
    mv build_output/temp.json build_output/results.json

# Add pyright field to results
jq -s '.[0] * {"pyright": .[1]}' build_output/results.json build_output/pyright_output.json > \\
    build_output/temp.json && mv build_output/temp.json build_output/results.json

chmod -R 777 .
exit 0"""


def get_examples() -> List[Dict[str, Any]]:
    """Return example script evaluations for few-shot learning."""
    return [
        {
            "script": "#!/bin/bash\n\n# Set the required Python version\nPYTHON_VERSION=\"3.7.0\"\n\n# Install the required Python version using pyenv\npyenv install -f $PYTHON_VERSION\npyenv global $PYTHON_VERSION\n\n# Install project dependencies using Poetry\npoetry install --no-root\n\n# Install optional dependencies if needed\n# Uncomment the following lines if you want to install optional dependencies\n# poetry install --with test\n# poetry install --with plot\n# poetry install --with xlsx\n# poetry install --with netw\n# poetry install --with visa\n# poetry install --with docs\n\n# Activate the Poetry environment\nsource $(poetry env info --path)/bin/activate\n\n# Install the package in editable mode\npip install -e .\n\n# Clean up\nrm -rf ~/.cache/pip\n",
            "output": "2.5.1)\n\nInspect or clean up the working tree at /tmp/python-build.20250204151129.339\nResults logged to /tmp/python-build.20250204151129.339.log\n\nLast 10 log lines:\nif test \"xupgrade\" != \"xno\"  ; then \\\n\tcase upgrade in \\\n\t\tupgrade) ensurepip=\"--upgrade\" ;; \\\n\t\tinstall|*) ensurepip=\"\" ;; \\\n\tesac; \\\n\tLD_LIBRARY_PATH=/tmp/python-build.20250204151129.339/Python-3.7.0 ./python -E -m ensurepip \\\n\t\t$ensurepip --root=/ ; \\\nfi\nSegmentation fault (core dumped)\nmake: *** [Makefile:1122: install] Error 139\n... (truncated)",
            "exit_code": 1,
            "issues_count": 0,
            "repository": "scikit-rf/scikit-rf",
            "target_reward": 0.0,
            "exploration_data": "Repository exploration for scikit-rf/scikit-rf:\n=== REPOSITORY EXPLORATION START ===\n--- Command 1 ---\nCommand: tree -a -L 3 --filelimit 100 || ls -R\nExit code:\n.\n|-- .git\n|   |-- FETCH_HEAD\n|   |-- HEAD\n|   |-- branches\n|   |-- config\n|   |-- description\n|   |-- hooks\n|   |   |-- applypatch-msg.sample\n|   |   |-- commit-msg.sample\n|   |   |-- fsmonitor-watchman.sample\n|   |   |-- post-update.sample\n|   |   |-- pre-applypatch.sample\n|   |   |-- pre-commit.sample\n|   |   |-- pre-merge-commit.sample\n|   |   |-- pre-push.sample\n|   |   |-- pre-rebase.sample\n|   |   |-- pre-receive.sample\n|   |   |-- prepare-commit-msg.sample\n|   |   |-- push-to-checkout.sample\n|   |   `-- update.sample\n|   |-- index\n|   |-- info\n|   |   `-- exclude\n|   |-- logs\n|   |   |-- HEAD\n|   |   `-- refs\n|   |-- objects\n|   |   |-- info\n|   |   `-- pack\n|   |-- packed-refs\n|   `-- refs\n|       |-- heads\n|       |-- remotes\n|       `-- tags\n|-- .github\n|   |-- FUNDING.yml\n|   |-- ISSUE_TEMPLATE\n|   |   |-- bug_report.md\n|   |   |-- feature_request.md\n|   |   `-- general-issue-.md\n|   |-- dependabot.yml\n|   |-- labeler.yml\n|   `-- workflows\n|       |-- PR_labeler.yml\n|       |-- codeql.yml\n|       |-- linting.yml\n|       |-- testing.yml\n|       |-- testing_notebooks.yml\n|       `-- urlchecker.yml\n|-- .gitignore\n|-- .pre-commit-config.yaml\n|-- .readthedocs.yml\n|-- CITATION.cff\n|-- INSTALL.txt\n|-- LICENSE.txt\n|-- README.md\n|-- apps\n|   `-- __init__.py\n|-- conda.recipe\n|   `-- meta.yaml\n|-- doc\n|   |-- Makefile\n|   |-- README.txt\n|   |-- gh-pages.py\n|   |-- make.bat\n|   |-- source\n|   |   |-- .gitignore\n|   |   |-- Makefile\n|   |   |-- _static\n|   |   |-- _templates\n|   |   |-- api\n|   |   |-- citations_ack\n|   |   |-- conf.py\n|   |   |-- contributing\n|   |   |-- examples\n|   |   |-- glossary.rst\n|   |   |-- index.rst\n|   |   |-- license.rst\n|   |   |-- skrf_Media_exemples.svg\n|   |   |-- skrf_Network_symbols.svg\n|   |   `-- tutorials\n|   `-- sphinxext\n|       |-- LICENSE.txt\n|       |-- MANIFEST.in\n|       |-- README.txt\n|       `-- tests\n|-- logo\n|   |-- scikit-rf-icon.png\n|   |-- scikit-rf-logo-flat-docs.png\n|   |-- scikit-rf-logo-flat-docs.svg\n|   |-- scikit-rf-logo-flat.png\n|   |-- scikit-rf-logo-flat.svg\n|   |-- scikit-rf-logo-flat_dark.svg\n|   |-- scikit-rf-title-flat.pdf\n|   |-- scikit-rf-title-flat.png\n|   |-- scikit-rf-title-flat.svg\n|   |-- scikit-rf-title-flat_dark.svg\n|   |-- skrfshirtwhite.png\n|   |-- smith_chart_simplified.svg\n|   `-- smith_chart_simplified_dark.svg\n|-- pyproject.toml\n|-- skrf\n|   |-- __init__.py\n|   |-- calibration\n|   |   |-- __init__.py\n|   |   |-- calibration.py\n|   |   |-- calibrationSet.py\n|   |   |-- deembedding.py\n|   |   `-- tests\n|   |-- circuit.py\n|   |-- constants.py\n|   |-- data\n|   |   |-- __init__.py\n|   |   |-- delay_short.s1p\n|   |   |-- ieeetrans.mplstyle\n|   |   |-- ind.s2p\n|   |   |-- line.s2p\n|   |   |-- ntwk1.s2p\n|   |   |-- one_port.cal\n|   |   |-- open.s2p\n|   |   |-- ring\\ slot\\ measured.s1p\n|   |   |-- ring\\ slot.s2p\n|   |   |-- ro,1.s1p\n|   |   |-- ro,2.s1p\n|   |   |-- ro,3.s1p\n|   |   |-- short.s1p\n|   |   |-- short.s2p\n|   |   |-- skrf.mplstyle\n|   |   |-- skrf2.mplstyle\n|   |   |-- skrf2_wide.mplstyle\n|   |   |-- skrfSesh.p\n|   |   |-- skrf_wide.mplstyle\n|   |   |-- tee.s3p\n|   |   |-- wr1p5,line.s2p\n|   |   |-- wr1p5,short.s1p\n|   |   |-- wr2p2,delayshort.s1p\n|   |   |-- wr2p2,line.s2p\n|   |   |-- wr2p2,line1.s2p\n|   |   `-- wr2p2,short.s1p\n|   |-- frequency.py\n|   |-- instances.py\n|   |-- io\n|   |   |-- __init__.py\n|   |   |-- citi.py\n|   |   |-- csv.py\n|   |   |-- general.py\n|   |   |-- mdif.py\n|   |   |-- metas.py\n|   |   |-- tests\n|   |   `-- touchstone.py\n|   |-- mathFunctions.py\n|   |-- media\n|   |   |-- __init__.py\n|   |   |-- circularWaveguide.py\n|   |   |-- coaxial.py\n|   |   |-- cpw.py\n|   |   |-- definedAEpTandZ0.py\n|   |   |-- device.py\n|   |   |-- distributedCircuit.py\n|   |   |-- freespace.py\n|   |   |-- media.py\n|   |   |-- mline.py\n|   |   |-- rectangularWaveguide.py\n|   |   `-- tests\n|   |-- network.py\n|   |-- networkSet.py\n|   |-- notebook\n|   |   |-- __init__.py\n|   |   |-- bokeh_.py\n|   |   |-- matplotlib_.py\n|   |   `-- utils.py\n|   |-- plotting.py\n|   |-- programs\n|   |   |-- plot_touchstone.py\n|   |   `-- readme.txt\n|   |-- qfactor.py\n|   |-- taper.py\n|   |-- tests\n|   |   |-- Agilent_E5071B.s4p\n|   |   |-- RS_ZNB8.s4p\n|   |   |-- cst_example_4ports.s4p\n|   |   |-- cst_example_6ports.s6p\n|   |   |-- cst_example_6ports_V2.s6p\n|   |   |-- cst_example_6ports_V2.ts\n|   |   |-- designer_variable_coupler_ideal_20deg.s4p\n|   |   |-- designer_variable_coupler_ideal_75deg.s4p\n|   |   |-- designer_wilkinson_splitter.s3p\n|   |   |-- fet.s2p\n|   |   |-- hfss_18.2.s3p\n|   |   |-- hfss_19.2.s10p\n|   |   |-- hfss_19.2.s8p\n|   |   |-- hfss_oneport.s1p\n|   |   |-- hfss_oneport_powerwave.s1p\n|   |   |-- hfss_threeport_DB.s3p\n|   |   |-- hfss_threeport_DB_50Ohm.s3p\n|   |   |-- hfss_threeport_MA.s3p\n|   |   |-- hfss_threeport_MA_50Ohm.s3p\n|   |   |-- hfss_threeport_MA_without_gamma_z0_50Ohm.s3p\n|   |   |-- hfss_twoport.s2p\n|   |   |-- load_gain_circle_ads.csv\n|   |   |-- load_stability_circle_ads.csv\n|   |   |-- maxgain_ads.csv\n|   |   |-- nf_circle_mwo.csv\n|   |   |-- ntwk.s32p\n|   |   |-- ntwk1.ntwk\n|   |   |-- ntwk1.s2p\n|   |   |-- ntwk2.s2p\n|   |   |-- ntwk3.s2p\n|   |   |-- ntwk4.s2p\n|   |   |-- ntwk4_n.s2p\n|   |   |-- ntwk_arbitrary_frequency.s2p\n|   |   |-- ntwk_noise.s2p\n|   |   |-- ntwk_pickle.zip\n|   |   |-- ntwks\n|   |   |-- ntwks.zip\n|   |   |-- qfactor_data\n|   |   |-- source_gain_circle_ads.csv\n|   |   |-- source_stability_circle_ads.csv\n|   |   |-- test_circuit.py\n|   |   |-- test_convenience.py\n|   |   |-- test_frequency.py\n|   |   |-- test_mathFunctions.py\n|   |   |-- test_network.py\n|   |   |-- test_networkSet.py\n|   |   |-- test_plotting.py\n|   |   |-- test_qfactor.py\n|   |   |-- test_static_data.py\n|   |   |-- test_tlineFunctions.py\n|   |   |-- test_util.py\n|   |   |-- test_vectorfitting.py\n|   |   |-- thru.s2p\n|   |   `-- tmp_skrf_oneport_powerwave.s1p\n|   |-- time.py\n|   |-- tlineFunctions.py\n|   |-- util.py\n|   |-- vectorFitting.py\n|   `-- vi\n|       |-- __init__.py\n|       |-- scpi_errors.py\n|       |-- tests\n|       |-- validators.py\n|       `-- vna\n`-- tox.ini\n\n46 directories, 197 files\nExit code: $?\n--- End Command 1 ---\n--- Command 2 ---\nCommand: for f in README.md INSTALL.md SETUP.md docs/INSTALL.md docs/SETUP.md; do if [ -f \"$f\" ]; then echo -e \"\\n=== $f ===\"; cat \"$f\"; fi; done\nExit code:\n\n=== README.md ===\n[![Code Testing](https://github.com/scikit-rf/scikit-rf/workflows/Code%20linting%20and%20testing/badge.svg)](https://github.com/scikit-rf/scikit-rf/actions?query=workflow%3A%22Code+linting+and+testing%22)\n[![Documentation Status](https://readthedocs.org/projects/scikit-rf/badge/?version=latest)](https://readthedocs.org/projects/scikit-rf/?badge=latest)\n[![Coverage Status](https://coveralls.io/repos/scikit-rf/scikit-rf/badge.png)](https://coveralls.io/r/scikit-rf/scikit-rf)\n[![License](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](./LICENSE.md)\n\n![PyPI - Downloads](https://img.shields.io/pypi/dm/scikit-rf)\n[![Conda Downloads](https://anaconda.org/conda-forge/scikit-rf/badges/downloads.svg)](https://anaconda.org/conda-forge/scikit-rf)\n\n## Description\n\n![scikit-rf_logo](doc/source/_static/scikit-rf-title-flat.png)\n\n**scikit-rf** (aka `skrf`) is an Open Source, BSD-licensed package for RF/Microwave engineering implemented\nin the Python programming language. It provides a modern, object-oriented library which is both\nflexible and scalable.\n\n* [Home Page](http://www.scikit-rf.org)\n* [Documentation](http://scikit-rf.readthedocs.org/)\n\n## Install\n\n[![PyPI version](https://img.shields.io/pypi/v/scikit-rf?style=flat&logo=pypi)](https://pypi.org/project/scikit-rf/)\n[![Conda-forge version](https://img.shields.io/conda/v/conda-forge/scikit-rf?style=flat&logo=anaconda)](https://img.shields.io/conda/v/conda-forge/scikit-rf)\n[![Conda version](https://anaconda.org/conda-forge/scikit-rf/badges/latest_release_date.svg)](https://anaco\n[truncated to 8000 characters]\n"
        },
        {
            "script": "#!/bin/bash\n\n# Set the required Python version\nPYTHON_VERSION=\"3.9.18\"\n\n# Install the required Python version using pyenv\npyenv install -f $PYTHON_VERSION\npyenv global $PYTHON_VERSION\n\n# Activate the Python environment\nexport PATH=\"/root/.pyenv/versions/$PYTHON_VERSION/bin:$PATH\"\n\n# Install project dependencies using Poetry\npoetry install --no-root\n\n# Install development dependencies\npip install -e .",
            "output": "ckend supports build_editable: started\n  Checking if build backend supports build_editable: finished with status 'done'\nERROR: Project file:///data/project has a 'pyproject.toml' and its build backend is missing the 'build_editable' hook. Since it does not have a 'setup.py' nor a 'setup.cfg', it cannot be installed in editable mode. Consider using a build backend that supports PEP 660.\n\n[notice] A new release of pip is available: 23.0.1 -> 25.0\n[notice] To update, run: pip install --upgrade pip\n... (truncated)",
            "exit_code": 1,
            "issues_count": 0,
            "repository": "scylladb/sphinx-scylladb-theme",
            "target_reward": 0.0,
            "exploration_data": "Repository exploration for scylladb/sphinx-scylladb-theme:\n=== REPOSITORY EXPLORATION START ===\n--- Command 1 ---\nCommand: tree -a -L 3 --filelimit 100 || ls -R\nExit code:\n.\n|-- .babelrc.json\n|-- .eslintrc.yml\n|-- .flake8\n|-- .git\n|   |-- FETCH_HEAD\n|   |-- HEAD\n|   |-- branches\n|   |-- config\n|   |-- description\n|   |-- hooks\n|   |   |-- applypatch-msg.sample\n|   |   |-- commit-msg.sample\n|   |   |-- fsmonitor-watchman.sample\n|   |   |-- post-update.sample\n|   |   |-- pre-applypatch.sample\n|   |   |-- pre-commit.sample\n|   |   |-- pre-merge-commit.sample\n|   |   |-- pre-push.sample\n|   |   |-- pre-rebase.sample\n|   |   |-- pre-receive.sample\n|   |   |-- prepare-commit-msg.sample\n|   |   |-- push-to-checkout.sample\n|   |   `-- update.sample\n|   |-- index\n|   |-- info\n|   |   `-- exclude\n|   |-- logs\n|   |   |-- HEAD\n|   |   `-- refs\n|   |-- objects\n|   |   |-- info\n|   |   `-- pack\n|   |-- packed-refs\n|   `-- refs\n|       |-- heads\n|       |-- remotes\n|       `-- tags\n|-- .github\n|   |-- dependabot.yaml\n|   `-- workflows\n|       |-- codeql-analysis.yaml\n|       |-- docs-links.yaml\n|       |-- docs-pages.yaml\n|       |-- docs-pr.yaml\n|       |-- multiversion-tests.yaml\n|       `-- theme-tests.yaml\n|-- .gitignore\n|-- .isort.cfg\n|-- .lycheeignore\n|-- .postcss.config.js\n|-- .pre-commit-config.yaml\n|-- .prettierignore\n|-- LICENSE\n|-- PYPI.rst\n|-- README.rst\n|-- config\n|   |-- paths.js\n|   |-- webpack.common.js\n|   `-- webpack.prod.js\n|-- deploy.sh\n|-- docs\n|   |-- Makefile\n|   |-- _utils\n|   |   |-- pyproject_template.toml\n|   |   `-- redirects.yaml\n|   `-- source\n|       |-- commands.rst\n|       |-- conf.py\n|       |-- configuration\n|       |-- contribute\n|       |-- deployment\n|       |-- examples\n|       |-- getting-started\n|       |-- index.rst\n|       `-- upgrade\n|-- extensions\n|   |-- sphinx-multiversion\n|   |   |-- .gitignore\n|   |   |-- LICENSE\n|   |   |-- README.md\n|   |   |-- requirements.txt\n|   |   |-- setup.py\n|   |   |-- sphinx_multiversion\n|   |   `-- tests\n|   `-- sphinx-scylladb-markdown\n|       |-- .gitignore\n|       |-- LICENSE\n|       |-- README.md\n|       |-- requirements.txt\n|       |-- setup.py\n|       `-- sphinx_scylladb_markdown\n|-- package-lock.json\n|-- package.json\n|-- poetry.lock\n|-- pyproject.toml\n|-- sphinx_scylladb_theme\n|   |-- 404.html\n|   |-- __init__.py\n|   |-- _version.py\n|   |-- breadcrumbs.html\n|   |-- content-navigation.html\n|   |-- contribute.html\n|   |-- extensions\n|   |   |-- __init__.py\n|   |   |-- hero_box.py\n|   |   |-- labels.py\n|   |   |-- multiversion.py\n|   |   |-- navigation.py\n|   |   |-- panel_box.py\n|   |   |-- topic_box.py\n|   |   |-- utils.py\n|   |   `-- validations.py\n|   |-- feedback.html\n|   |-- footer.html\n|   |-- header.html\n|   |-- last-updated.html\n|   |-- layout.html\n|   |-- lexers\n|   |   |-- __init__.py\n|   |   |-- cql.py\n|   |   `-- ditaa.py\n|   |-- local-scripts.html\n|   |-- notice.html\n|   |-- promo-banner.html\n|   |-- scylladb-scripts.html\n|   |-- secondary-side-nav.html\n|   |-- side-nav-toggle.html\n|   |-- side-nav.html\n|   |-- static\n|   |   |-- css\n|   |   |-- img\n|   |   `-- js\n|   |-- theme.conf\n|   |-- utils.py\n|   |-- version-warning.html\n|   `-- versions.html\n|-- src\n|   |-- css\n|   |   |-- base\n|   |   |-- components\n|   |   `-- main.scss\n|   |-- img\n|   |   |-- .gitkeep\n|   |   |-- banner-background.svg\n|   |   |-- favicon-228x228.png\n|   |   |-- favicon-32x32.png\n|   |   |-- favicon.ico\n|   |   |-- icons\n|   |   |-- logo-docs.svg\n|   |   |-- logo-scylla-horizontal-RGB.svg\n|   |   |-- mascots\n|   |   `-- menu.svg\n|   `-- js\n|       |-- collapse.js\n|       |-- images.js\n|       |-- index.js\n|       |-- links.js\n|       |-- promo-banner.js\n|       |-- secondary-sidebar.js\n|       |-- sidebar.js\n|       `-- tables.js\n`-- tests\n    |-- extensions\n    |   |-- test_extensions_utils.py\n    |   |-- test_hero_box.py\n    |   |-- test_panel_box.py\n    |   |-- test_topic_box.py\n    |   `-- test_validations.py\n    |-- test_sphinx_scylladb_theme.py\n    |-- test_utils.py\n    `-- test_version.py\n\n48 directories, 123 files\nExit code: $?\n--- End Command 1 ---\n--- Command 2 ---\nCommand: for f in README.md INSTALL.md SETUP.md docs/INSTALL.md docs/SETUP.md; do if [ -f \"$f\" ]; then echo -e \"\\n=== $f ===\"; cat \"$f\"; fi; done\nExit code:\nExit code: $?\n--- End Command 2 ---\n--- Command 3 ---\nCommand: find . -type f \\( -name \"*requirements*.txt\" -o -name \"setup.py\" -o -name \"pyproject.toml\" -o -name \"setup.cfg\" -o -name \"tox.ini\" \\) | while read f; do echo -e \"\\n=== $f ===\"; cat \"$f\"; done\nExit code:\n\n=== ./extensions/sphinx-multiversion/setup.py ===\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nimport os.path\n\nfrom setuptools import setup\n\nwith open(os.path.join(os.path.dirname(__file__), \"README.md\")) as f:\n    readme = f.read()\n\nsetup(\n    name=\"sphinx-multiversion-scylla\",\n    description=\"Add support for multiple versions to sphinx\",\n    long_description=readme,\n    long_description_content_type=\"text/markdown\",\n    classifiers=[\n        \"License :: OSI Approved :: BSD License\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.6\",\n        \"Programming Language :: Python :: 3.7\",\n    ],\n    author=\"Jan Holthuis\",\n    author_email=\"holthuis.jan@googlemail.com\",\n    url=\"https://holzhaus.github.io/sphinx-multiversion/\",\n    version=\"0.3.1\",\n    install_requires=[\"sphinx >= 2.1\"],\n    license=\"BSD\",\n    packages=[\"sphinx_multiversion\"],\n    entry_points={\n        \"console_scripts\": [\n            \"sphinx-multiversion=sphinx_multiversion:main\",\n        ],\n    },\n)\n\n=== ./extensions/sphinx-multiversion/requirements.txt ===\nsphinx\n\n=== ./extensions/sphinx-scylladb-markdown/setup.py ===\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nimport os.path\n\nfrom setuptools import setup\n\nwith open(os.path.join(os.path.dirname(__file__), \"README.md\")) as f:\n    readme = f.read()\n\nsetup(\n    name=\"sphinx-scylladb-markdown\",\n    description=\"Sphinx extension for ScyllaDB documentation with enhanced Markdown support through MystParser and recommonmark.\",\n    long_description=readme,\n    long_description_content_type=\"text/markdown\",\n    author=\"David Garcia\",\n    author_email=\"hi@davidgarcia.dev\",\n    url=\"https://github.com/scylladb/sphinx-scylladb-theme\",\n    version=\"0.1.3\",\n    install_requires=[\n        \"sphinx >= 2.1\",\n        \"recommonmark == 0.7.1\",\n        \"sphinx-markdown-tables == 0.0.17\",\n        \"myst-parser >= 2.0.0\"\n    ],\n    packages=[\"sphinx_scylladb_markdown\"],\n)\n\n=== ./extensions/sphinx-scylladb-markdown/requirements.txt ===\nsphinx\n\n=== ./pyproject.toml ===\n[tool.poetry]\nname = \"sphinx-scylladb-theme\"\nversion = \"1.7.2\"\ndescription = \"A Sphinx Theme for ScyllaDB documentation projects\"\nauthors = [\"David Garc\u00eda <hi@davidgarcia.dev>\"]\nexclude = [\".github\", \"config\", \"docs\", \"extensions\", \".postcss.config.js\", \".prettierrc.json\", \"deploy.sh\", \"src\", \"package.json\", \"package-lock.json\"]\nreadme = \"PYPI.rst\"\n\n[tool.poetry.dependencies]\npython = \"^3.9\"\nsphinx-collapse = \"^0.1.1\"\nsphinx-copybutton = \"^0.5.2\"\nbeautifulsoup4 = \"^4.12.2\"\nsphinx-tabs = \"^3.4.1\"\npyyaml = \"^6.0.1\"\nSphinx-Substitution-Extensions = \"^2022.2.16\"\nsphinx-notfound-page = \"^1.0.0\"\nimportlib-metadata = \">=6.8,<8.0\"\n\n[tool.poetry.dev-dependencies]\npytest = \"^8.1.1\"\nsphinx-autobuild = \"^2024.2.4\"\npre-commit = \"^3.7.0\"\nmyst-parser = \"^2.0.0\"\nsetuptools = \"^69.5.1\"\nsphinx-multiversion-scylla = \"^0.3.1\"\nsphinx-sitemap = \"^2.5.1\"\nredirects_cli =\"^0.1.3\"\n\n[build-system]\nrequires = [\"poetry>=0.12\"]\nbuild-backend = \"poetry.masonry.api\"\nExit code: $?\n--- End Command 3 ---\n--- Command 4 ---\nCommand: find . -type f -name \"*.py\" -exec grep -l \"python_version\\|python_requires\" {} \\;\nExit code:\nExit code: $?\n--- End Command 4 ---\n--- Command 5 ---\nCommand: find . -type f \\( -name \".env*\" -o -name \"*.env\" -o -name \"Dockerfile*\" \\) | while read f; do echo -e \"\\n=== $f ===\"; cat \"$f\"; done\nExit code:\nExit code: $?\n--- End Command 5 ---\n=== REPOSITORY EXPLORATION END ===\n\n"
        },
        {
            "script": "# #!/bin/bash\n\n# Set up the Python development environment for the Qiita repository\n\n# Install required system packages\napt-get update -y && apt-get install -y \\\n    postgresql-13 \\\n    postgresql-client-13 \\\n    redis-server \\\n    nginx \\\n    libgfortran5 \\\n    python3-pip\n\n# Create a conda environment for Qiita\nconda config --add channels conda-forge\nconda create -q --yes -n qiita python=3.9 pip libgfortran numpy nginx cython redis\n\n# Activate the conda environment\nsource activate qiita\n\n# Install Python dependencies from setup.py\npip install .\n\n# Start PostgreSQL and Redis services\nservice postgresql start\nservice redis-server start\n\n# Print success message\necho \"Qiita development environment has been set up successfully.\"\necho \"To activate the environment, run: source activate qiita\"\necho \"PostgreSQL and Redis services are running.\"",
            "output": "3.3 kB]\nGet:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2906 kB]\nGet:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\nGet:20 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\nFetched 36.2 MB in 3s (10.7 MB/s)\nReading package lists...\nReading package lists...\nBuilding dependency tree...\nReading state information...\nE: Unable to locate package postgresql-13\nE: Unable to locate package postgresql-client-13\n... (truncated)",
            "exit_code": 100,
            "issues_count": 0,
            "repository": "qiita-spots/qiita",
            "target_reward": 0.0,
            "exploration_data": "Repository exploration for qiita-spots/qiita:\n=== REPOSITORY EXPLORATION START ===\n--- Command 1 ---\nCommand: tree -a -L 3 --filelimit 100 || ls -R\nExit code:\n.\n|-- .coveragerc\n|-- .git\n|   |-- FETCH_HEAD\n|   |-- HEAD\n|   |-- branches\n|   |-- config\n|   |-- description\n|   |-- hooks\n|   |   |-- applypatch-msg.sample\n|   |   |-- commit-msg.sample\n|   |   |-- fsmonitor-watchman.sample\n|   |   |-- post-update.sample\n|   |   |-- pre-applypatch.sample\n|   |   |-- pre-commit.sample\n|   |   |-- pre-merge-commit.sample\n|   |   |-- pre-push.sample\n|   |   |-- pre-rebase.sample\n|   |   |-- pre-receive.sample\n|   |   |-- prepare-commit-msg.sample\n|   |   |-- push-to-checkout.sample\n|   |   `-- update.sample\n|   |-- index\n|   |-- info\n|   |   `-- exclude\n|   |-- logs\n|   |   |-- HEAD\n|   |   `-- refs\n|   |-- objects\n|   |   |-- info\n|   |   `-- pack\n|   |-- packed-refs\n|   `-- refs\n|       |-- heads\n|       |-- remotes\n|       `-- tags\n|-- .github\n|   `-- workflows\n|       `-- qiita-ci.yml\n|-- .gitignore\n|-- CHANGELOG.md\n|-- CODE-OF-CONDUCT.md\n|-- CONTRIBUTING.md\n|-- INSTALL.md\n|-- LICENSE\n|-- MANIFEST.in\n|-- README.rst\n|-- logos\n|   |-- qiita-pointer.ai\n|   |-- qiita-pointer.png\n|   |-- qiita.ai\n|   |-- qiita.png\n|   |-- qiita_black.ai\n|   |-- qiita_black.png\n|   |-- qiita_cancer.ai\n|   `-- qiita_dependencies.ai\n|-- notebooks\n|   `-- resource-allocation\n|       |-- 072023.ipynb\n|       |-- 102023.1.ipynb\n|       |-- 102023.ipynb\n|       |-- 112023.ipynb\n|       |-- generate-allocation-summary-arrays.py\n|       `-- generate-allocation-summary.py\n|-- qiita_core\n|   |-- __init__.py\n|   |-- configuration_manager.py\n|   |-- environment_manager.py\n|   |-- exceptions.py\n|   |-- qiita_settings.py\n|   |-- support_files\n|   |   |-- ci_root.key\n|   |   |-- ci_rootca.crt\n|   |   |-- ci_rootca.srl\n|   |   |-- ci_server.crt\n|   |   |-- ci_server.csr\n|   |   |-- ci_server.key\n|   |   |-- config_test.cfg\n|   |   `-- config_test.cfg.enc\n|   |-- testing.py\n|   |-- tests\n|   |   |-- __init__.py\n|   |   |-- test_configuration_manager.py\n|   |   `-- test_util.py\n|   `-- util.py\n|-- qiita_db\n|   |-- __init__.py\n|   |-- analysis.py\n|   |-- archive.py\n|   |-- artifact.py\n|   |-- base.py\n|   |-- commands.py\n|   |-- download_link.py\n|   |-- environment_manager.py\n|   |-- exceptions.py\n|   |-- handlers\n|   |   |-- __init__.py\n|   |   |-- analysis.py\n|   |   |-- archive.py\n|   |   |-- artifact.py\n|   |   |-- core.py\n|   |   |-- oauth2.py\n|   |   |-- plugin.py\n|   |   |-- prep_template.py\n|   |   |-- processing_job.py\n|   |   |-- reference.py\n|   |   |-- sample_information.py\n|   |   |-- studies.py\n|   |   |-- tests\n|   |   |-- user.py\n|   |   `-- util.py\n|   |-- investigation.py\n|   |-- logger.py\n|   |-- meta_util.py\n|   |-- metadata_template\n|   |   |-- __init__.py\n|   |   |-- base_metadata_template.py\n|   |   |-- constants.py\n|   |   |-- prep_template.py\n|   |   |-- sample_template.py\n|   |   |-- test\n|   |   `-- util.py\n|   |-- ontology.py\n|   |-- portal.py\n|   |-- processing_job.py\n|   |-- reference.py\n|   |-- software.py\n|   |-- sql_connection.py\n|   |-- study.py\n|   |-- support_files\n|   |   |-- parameter_files\n|   |   |-- patches\n|   |   |-- populate_test_db.sql\n|   |   |-- qiita-db-settings.sql\n|   |   |-- qiita-db-unpatched.dbs\n|   |   |-- qiita-db-unpatched.sql\n|   |   |-- qiita-db.dbs\n|   |   |-- qiita-db.html\n|   |   |-- test_data\n|   |   `-- work_data\n|   |-- test\n|   |   |-- __init__.py\n|   |   |-- support_files\n|   |   |-- test_analysis.py\n|   |   |-- test_archive.py\n|   |   |-- test_artifact.py\n|   |   |-- test_base.py\n|   |   |-- test_commands.py\n|   |   |-- test_data\n|   |   |-- test_logger.py\n|   |   |-- test_meta_util.py\n|   |   |-- test_ontology.py\n|   |   |-- test_portal.py\n|   |   |-- test_processing_job.py\n|   |   |-- test_reference.py\n|   |   |-- test_setup.py\n|   |   |-- test_software.py\n|   |   |-- test_sql.py\n|   |   |-- test_sql_connection.py\n|   |   |-- test_study.py\n|   |   |-- test_user.py\n|   |   `-- test_util.py\n|   |-- user.py\n|   `-- util.py\n|-- qiita_pet\n|   |-- __init__.py\n|   |-- exceptions.py\n|   |-- handlers\n|   |   |-- __init__.py\n|   |   |-- admin_processing_job.py\n|   |   |-- analysis_handlers\n|   |   |-- api_proxy\n|   |   |-- artifact_handlers\n|   |   |-- auth_handlers.py\n|   |   |-- base_handlers.py\n|   |   |-- download.py\n|   |   |-- logger_handlers.py\n|   |   |-- ontology.py\n|   |   |-- portal.py\n|   |   |-- prep_template.py\n|   |   |-- public.py\n|   |   |-- qiita_redbiom.py\n|   |   |-- rest\n|   |   |-- software.py\n|   |   |-- stats.py\n|   |   |-- study_handlers\n|   |   |-- upload.py\n|   |   |-- user_handlers.py\n|   |   |-- util.py\n|   |   `-- websocket_handlers.py\n|   |-- nginx_example.conf\n|   |-- portal.py\n|   |-- results\n|   |   `-- admin\n|   |-- static\n|   |   |-- css\n|   |   |-- img\n|   |   |-- js\n|   |   |-- qiita_data_terms_of_use.html\n|   |   `-- vendor\n|   |-- supervisor_example.conf\n|   |-- support_files\n|   |   |-- config_portal.cfg\n|   |   `-- doc\n|   |-- templates\n|   |   |-- 404.html\n|   |   |-- admin_approval.html\n|   |   |-- admin_processing_job.html\n|   |   |-- analysis_description.html\n|   |   |-- analysis_selected.html\n|   |   |-- artifact_ajax\n|   |   |-- change_lost_pass.html\n|   |   |-- change_password.html\n|   |   |-- compute_wait.html\n|   |   |-- create_user.html\n|   |   |-- ebi_submission.html\n|   |   |-- edit_study.html\n|   |   |-- error.html\n|   |   |-- error_log.html\n|   |   |-- iframe.html\n|   |   |-- index.html\n|   |   |-- list_analyses.html\n|   |   |-- list_studies.html\n|   |   |-- login.html\n|   |   |-- lost_pass.html\n|   |   |-- portals_edit.html\n|   |   |-- public.html\n|   |   |-- redbiom.html\n|   |   |-- sample_validation.html\n|   |   |-- select_commands.html\n|   |   |-- sitebase.html\n|   |   |-- software.html\n|   |   |-- stats.html\n|   |   |-- study_ajax\n|   |   |-- study_base.html\n|   |   |-- text_file.html\n|   |   |-- upload.html\n|   |   |-- user_messages.html\n|   |   |-- user_profile.html\n|   |   |-- user_verified.html\n|   |   |-- vamps_submission.html\n|   |   |-- waiting.html\n|   |   `-- workflows.html\n|   |-- test\n|   |   |-- __init__.py\n|   |   |-- rest\n|   |   |-- test_admin_processing_job_handlers.py\n|   |   |-- test_auth_handlers.py\n|   |   |-- test_base_handlers.py\n|   |   |-- test_download.py\n|   |   |-- test_logger.py\n|   |   |-- test_ontology.py\n|   |   |-- test_portal.py\n|   |   |-- test_prep_template.py\n|   |   |-- test_public.py\n|   |   |-- test_qiita_redbiom.py\n|   |   |-- test_software.py\n|   |   |-- test_upload.py\n|   |   |-- test_user_handlers.py\n|   |   |-- test_util.py\n|   |   |-- test_websocket_handlers.py\n|   |   `-- tornado_test_base.py\n|   |-- util.py\n|   `-- webserver.py\n|-- qiita_ware\n|   |-- __init__.py\n|   |-- commands.py\n|   |-- ebi.py\n|   |-- exceptions.py\n|   |-- metadata_pipeline.py\n|   |-- private_plugin.py\n|   `-- test\n|       |-- __init__.py\n|       |-- test_commands.py\n|       |-- test_data\n|       |-- test_ebi.py\n|       |-- test_metadata_pipeline.py\n|       `-- test_private_plugin.py\n|-- scripts\n|   |-- all-qiita-cron-job\n|   |-- qiita\n|   |-- qiita-auto-processing\n|   |-- qiita-cron-job\n|   |-- qiita-env\n|   |-- qiita-private-launcher\n|   |-- qiita-private-launcher-slurm\n|   |-- qiita-private-plugin\n|   |-- qiita-recover-jobs\n|   `-- qiita-test-install\n|-- setup.py\n`-- test_data_studies\n    |-- commands.sh\n    `-- studies\n        |-- 1235\n        `-- 895\n\n63 directories, 231 files\nExit code: $?\n--- End Command 1 ---\n--- Command 2 ---\nCommand: for f in README.md INSTALL.md SETUP.md docs/INSTALL.md docs/SETUP.md; do if [ -f \"$f\" ]; then echo -e \"\\n=== $f ===\"; cat \"$f\"; fi; done\nExit code:\n\n=== INSTALL.md ===\n\nQiita installation \n==================\n\nQiita is pip installable, but depends on specific versions of python and non-python packages that must be installed first. We strongly recommend using virtual environments; a popular solution to manage them is [miniconda](http://conda.pydata.org/miniconda.html), a lightweight version of the virtual environment, python distribution, and package manager anaconda. The\n[truncated to 8000 characters]\n"
        },
        {
            "script": "",
            "output": "",
            "exit_code": 0,
            "issues_count": 68,
            "repository": "yt-project/unyt",
            "target_reward": 0.25,
            "exploration_data": "Repository exploration for yt-project/unyt:\n=== REPOSITORY EXPLORATION START ===\n--- Command 1 ---\nCommand: tree -a -L 3 --filelimit 100 || ls -R\nExit code:\n.\n|-- .editorconfig\n|-- .git\n|   |-- FETCH_HEAD\n|   |-- HEAD\n|   |-- branches\n|   |-- config\n|   |-- description\n|   |-- hooks\n|   |   |-- applypatch-msg.sample\n|   |   |-- commit-msg.sample\n|   |   |-- fsmonitor-watchman.sample\n|   |   |-- post-update.sample\n|   |   |-- pre-applypatch.sample\n|   |   |-- pre-commit.sample\n|   |   |-- pre-merge-commit.sample\n|   |   |-- pre-push.sample\n|   |   |-- pre-rebase.sample\n|   |   |-- pre-receive.sample\n|   |   |-- prepare-commit-msg.sample\n|   |   |-- push-to-checkout.sample\n|   |   `-- update.sample\n|   |-- index\n|   |-- info\n|   |   `-- exclude\n|   |-- logs\n|   |   |-- HEAD\n|   |   `-- refs\n|   |-- objects\n|   |   |-- info\n|   |   `-- pack\n|   |-- packed-refs\n|   `-- refs\n|       |-- heads\n|       |-- remotes\n|       `-- tags\n|-- .git-blame-ignore-revs\n|-- .gitattributes\n|-- .github\n|   |-- ISSUE_TEMPLATE.md\n|   |-- dependabot.yml\n|   `-- workflows\n|       |-- bleeding-edge.yaml\n|       `-- ci.yml\n|-- .gitignore\n|-- .mailmap\n|-- .pre-commit-config.yaml\n|-- .readthedocs.yaml\n|-- AUTHORS.rst\n|-- CONTRIBUTING.rst\n|-- HISTORY.rst\n|-- LICENSE\n|-- MANIFEST.in\n|-- README.rst\n|-- benchmarks\n|   |-- README.txt\n|   `-- bench.py\n|-- codemeta.json\n|-- docs\n|   |-- Makefile\n|   |-- _static\n|   |   |-- mpl_fig1.png\n|   |   |-- mpl_fig2.png\n|   |   |-- mpl_fig3.png\n|   |   |-- mpl_fig4.png\n|   |   |-- mpl_fig5.png\n|   |   |-- yt_icon.png\n|   |   |-- yt_logo.png\n|   |   `-- yt_logo_small.png\n|   |-- authors.rst\n|   |-- citation.rst\n|   |-- conf.py\n|   |-- contributing.rst\n|   |-- extensions\n|   |   `-- show_all_units.py\n|   |-- history.rst\n|   |-- index.rst\n|   |-- installation.rst\n|   |-- make.bat\n|   |-- requirements.txt\n|   |-- unit_listing.rst\n|   `-- usage.rst\n|-- paper\n|   |-- apply.png\n|   |-- benchmark_plot.py\n|   |-- binary_different_units.png\n|   |-- binary_same_units.png\n|   |-- paper-final.pdf\n|   |-- paper.bib\n|   |-- paper.md\n|   |-- ufunc.png\n|   |-- ufuncout.png\n|   `-- unary.png\n|-- pyproject.toml\n|-- tox.ini\n`-- unyt\n    |-- __init__.py\n    |-- _array_functions.py\n    |-- _deprecation.py\n    |-- _mpl_array_converter\n    |   `-- __init__.py\n    |-- _on_demand_imports.py\n    |-- _parsing.py\n    |-- _physical_ratios.py\n    |-- _pint_conversions.py\n    |-- _unit_lookup_table.py\n    |-- array.py\n    |-- dask_array.py\n    |-- dimensions.py\n    |-- equivalencies.py\n    |-- exceptions.py\n    |-- mpl_interface.py\n    |-- physical_constants.py\n    |-- testing.py\n    |-- tests\n    |   |-- __init__.py\n    |   |-- data\n    |   |-- test_array_functions.py\n    |   |-- test_dask_arrays.py\n    |   |-- test_define_unit.py\n    |   |-- test_mpl_interface.py\n    |   |-- test_no_duplicates.py\n    |   |-- test_unit_registry.py\n    |   |-- test_unit_systems.py\n    |   |-- test_units.py\n    |   |-- test_unyt_array.py\n    |   `-- test_unyt_testing.py\n    |-- unit_object.py\n    |-- unit_registry.py\n    |-- unit_symbols.py\n    `-- unit_systems.py\n\n24 directories, 106 files\nExit code: $?\n--- End Command 1 ---\n--- Command 2 ---\nCommand: for f in README.md INSTALL.md SETUP.md docs/INSTALL.md docs/SETUP.md; do if [ -f \"$f\" ]; then echo -e \"\\n=== $f ===\"; cat \"$f\"; fi; done\nExit code:\nExit code: $?\n--- End Command 2 ---\n--- Command 3 ---\nCommand: find . -type f \\( -name \"*requirements*.txt\" -o -name \"setup.py\" -o -name \"pyproject.toml\" -o -name \"setup.cfg\" -o -name \"tox.ini\" \\) | while read f; do echo -e \"\\n=== $f ===\"; cat \"$f\"; done\nExit code:\n\n=== ./docs/requirements.txt ===\nnumpy\nsympy\nmatplotlib\nsphinx\n\n=== ./tox.ini ===\n[tox]\nenvlist = py39-docs,begin,py39-dependencies,py39-versions,py{39,310,311,312},py39-unyt-module-test-function,end\nisolated_build = True\n\n[gh-actions]\npython =\n    3.9: py39, py39-docs, py39-dependencies, py39-versions, py39-unyt-module-test-function\n    3.10: py310\n    3.11: py311\n    3.12: py312\n\n[testenv]\npackage = wheel\nwheel_build_env = .pkg\nsetenv =\n    PYTHONPATH = {toxinidir}\n    MPLBACKEND = agg\nrecreate = true\ndepends = begin\ndeps =\n    pytest\n    h5py\n    !py39: pint\n    !py39: astropy!=6.1.1\n    coverage[toml]>=5.0\n    pytest-cov\n    pytest-doctestplus\n    matplotlib!=3.5.0\n    docutils\n    dask[array,diagnostics]\ncommands =\n    pytest --cov=unyt --cov-append --doctest-modules --doctest-plus --doctest-rst --basetemp={envtmpdir}\n    coverage report --omit='.tox/*'\n\n[testenv:py39]\n# skip doctest on py39 because doctests require numpy>=2.0 and all optional deps,\n# but some of our optional deps (pint, astropy) don't have a version that support\n# both numpy>=2.0 and Python 3.9\ncommands=\n    pytest --cov=unyt --cov-append --basetemp={envtmpdir}\n    coverage report --omit='.tox/*'\n\n[testenv:py39-versions]\ndeps =\n    docutils\n    pytest\n    sympy==1.7\n    numpy==1.19.3\n    h5py==3.0.0\n    pint==0.9\n    astropy==4.0.4\n    matplotlib==3.3.3\n    coverage[toml]\n    pytest-cov\n    pytest-doctestplus\n    dask[array,diagnostics]==2021.04.1\ncommands =\n    # don't do doctests on old numpy versions\n    pytest --cov=unyt --cov-append --basetemp={envtmpdir}\n    coverage report --omit='.tox/*'\n\n[testenv:py39-dependencies]\ndeps =\n    docutils\n    pytest\n    coverage[toml]\n    pytest-cov\n    pytest-doctestplus\ndepends = begin\ncommands =\n    # don't do doctests in rst files due to lack of way to specify optional\n    # test dependencies there\n    pytest --cov=unyt --cov-append --doctest-modules --doctest-plus --basetemp={envtmpdir}\n    coverage report --omit='.tox/*'\n\n[testenv:py39-docs]\nallowlist_externals = make\nchangedir = docs\ndeps =\n    pytest\n    sphinx\n    matplotlib!=3.5.0\n    dask[array,diagnostics]\ncommands =\n    make clean\n    python -m sphinx -M html \".\" \"_build\" -W\n\n[testenv:py39-unyt-module-test-function]\ndepends = py39\ncommands =\n    python -c 'import unyt; unyt.test()'\n\n[testenv:begin]\ncommands =\n    coverage erase\ndepends =\nskip_install = true\ndeps =\n    coverage[toml]\n\n[testenv:end]\ncommands =\n    coverage report --omit='.tox/*'\n    coverage html --omit='.tox/*'\nskip_install = true\ndepends = py{39,310,311,312}\ndeps =\n    coverage[toml]\n\n=== ./pyproject.toml ===\n[build-system]\nrequires = [\n  \"setuptools>=61.2\",\n  \"setuptools_scm[toml]>=7.0.1\",\n]\n\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"unyt\"\ndescription = \"A package for handling numpy arrays with units\"\nauthors = [\n    { name = \"The yt project\", email = \"yt-dev@python.org\" },\n]\nclassifiers = [\n    \"Development Status :: 5 - Production/Stable\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: BSD License\",\n    \"Natural Language :: English\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: Implementation :: CPython\",\n]\nkeywords = [\n    \"unyt\",\n]\nrequires-python = \">=3.9\"\ndependencies = [\n    \"numpy>=1.19.3, <3.0\",\n    \"sympy>=1.7\",\n    \"packaging>=20.9\",\n]\ndynamic = [\n    \"version\",\n]\n\n[project.readme]\nfile = \"README.rst\"\ncontent-type = \"text/x-rst\"\n\n[project.license]\ntext = \"BSD-3-Clause\"\n\n[project.urls]\nHomepage = \"https://github.com/yt-project/unyt\"\nDocumentation = \"https://unyt.readthedocs.io/en/stable/index.html\"\nChangelog = \"https://unyt.readthedocs.io/en/stable/history.html\"\n\n[tool.setuptools]\ninclude-package-data = true\nzip-safe = false\nlicense-files = [\n    \"LICENSE\",\n]\n\n[tool.setuptools.packages.find]\ninclude = [\n    \"unyt\",\n    \"unyt.tests\",\n    \"unyt.tests.data\",\n    \"unyt._mpl_array_converter\",\n]\nnamespaces = false\n\n[tool.setuptools.package-data]\nunyt = [\n    \"tests/data/old_json_registry.txt\",\n]\n\n\n[tool.black]\nexclude = '''\n(\n  /(\n      \\.eggs\n    | \\.git\n    | \\.hg\n    | \\.mypy_cache\n    | \\.tox\n    | \\.venv\n    | _build\n    | buck-out\n    | build\n    | dist\n    | _version.py\n  )\n)\n'''\n\n[tool.ruff]\nexclude = [\n    \".*/\",\n    \"benchmarks/*.py\",\n    \"paper/*.py\",\n    \"*/_version.py\",\n    \"*/__init__.py\",\n]\n[tool.ruff.lint]\nignore = [\n    \"E501\",\n    \"B904\",\n]\nselect = [\n    \"E\",\n    \"F\",\n    \"W\",\n    \"C4\",  # flake8-comprehensions\n    \"B\",   # flake8-bugbear\n   \n[truncated to 8000 characters]\n"
        },
        {
            "script": "eval \"$(pyenv init -)\"\nls\ncat pyproject.toml\npyenv versions\npip install autograd\npip install \"autograd[scipy]\"\n# python -c \"import autograd; import scipy\"\npip install six\n# python -c \"import autograd; import scipy\"\n# pip install numpy==1.21.6\n# pip install numpy==1.20.3\napt-get install -y python3-distutils\n# pip install numpy==1.20.3\n# apt-get install -y python3.13-distutils\n# apt-get install -y python3.12-distutils\napt-get install -y python3.10-distutils\npyenv global 3.10.13\n# pip install numpy==1.20.3\n# pip install numpy==1.19.5\n# pip install numpy==1.19.2\n# pip install numpy==1.18.5\n# pip install numpy==1.17.0\n# pip install numpy==1.16.6\n# pip install numpy==1.15.4\n# pip install numpy==1.14.6\n# pip install numpy==1.13.3\n# pip install numpy==1.12.1\n# pip install numpy==1.11.3\n# pip install numpy==1.10.4\n# pip install numpy==1.9.3\n# pip install numpy==1.8.2\n# pip install numpy==1.7.2",
            "output": "",
            "exit_code": 0,
            "issues_count": 51,
            "repository": "hips/autograd",
            "target_reward": 0.5,
            "exploration_data": "Repository exploration for hips/autograd:\n=== REPOSITORY EXPLORATION START ===\n--- Command 1 ---\nCommand: tree -a -L 3 --filelimit 100 || ls -R\nExit code:\n.\n|-- .git\n|   |-- FETCH_HEAD\n|   |-- HEAD\n|   |-- branches\n|   |-- config\n|   |-- description\n|   |-- hooks\n|   |   |-- applypatch-msg.sample\n|   |   |-- commit-msg.sample\n|   |   |-- fsmonitor-watchman.sample\n|   |   |-- post-update.sample\n|   |   |-- pre-applypatch.sample\n|   |   |-- pre-commit.sample\n|   |   |-- pre-merge-commit.sample\n|   |   |-- pre-push.sample\n|   |   |-- pre-rebase.sample\n|   |   |-- pre-receive.sample\n|   |   |-- prepare-commit-msg.sample\n|   |   |-- push-to-checkout.sample\n|   |   `-- update.sample\n|   |-- index\n|   |-- info\n|   |   `-- exclude\n|   |-- logs\n|   |   |-- HEAD\n|   |   `-- refs\n|   |-- objects\n|   |   |-- info\n|   |   `-- pack\n|   |-- packed-refs\n|   `-- refs\n|       |-- heads\n|       |-- remotes\n|       `-- tags\n|-- .github\n|   `-- workflows\n|       |-- check.yml\n|       |-- publish.yml\n|       `-- test.yml\n|-- .gitignore\n|-- CONTRIBUTING.md\n|-- MANIFEST.in\n|-- README.md\n|-- autograd\n|   |-- __init__.py\n|   |-- builtins.py\n|   |-- core.py\n|   |-- differential_operators.py\n|   |-- extend.py\n|   |-- misc\n|   |   |-- __init__.py\n|   |   |-- fixed_points.py\n|   |   |-- flatten.py\n|   |   |-- optimizers.py\n|   |   `-- tracers.py\n|   |-- numpy\n|   |   |-- __init__.py\n|   |   |-- fft.py\n|   |   |-- linalg.py\n|   |   |-- numpy_boxes.py\n|   |   |-- numpy_jvps.py\n|   |   |-- numpy_vjps.py\n|   |   |-- numpy_vspaces.py\n|   |   |-- numpy_wrapper.py\n|   |   `-- random.py\n|   |-- scipy\n|   |   |-- __init__.py\n|   |   |-- integrate.py\n|   |   |-- linalg.py\n|   |   |-- misc.py\n|   |   |-- signal.py\n|   |   |-- special.py\n|   |   `-- stats\n|   |-- test_util.py\n|   |-- tracer.py\n|   |-- util.py\n|   `-- wrap_util.py\n|-- benchmarks\n|   |-- __init__.py\n|   |-- asv.conf.json.sample\n|   |-- bench_core.py\n|   |-- bench_mem.py\n|   |-- bench_numpy_vjps.py\n|   |-- bench_rnn.py\n|   `-- bench_util.py\n|-- conda_recipe\n|   `-- conda.yaml\n|-- docs\n|   |-- tutorial.md\n|   `-- updateguide.md\n|-- examples\n|   |-- __init__.py\n|   |-- bayesian_neural_net.png\n|   |-- bayesian_neural_net.py\n|   |-- bayesian_optimization.py\n|   |-- black_box_svi.py\n|   |-- convnet.py\n|   |-- data.py\n|   |-- data_mnist.py\n|   |-- deep_gaussian_process.py\n|   |-- define_gradient.py\n|   |-- dot_graph.py\n|   |-- fixed_points.py\n|   |-- fluidsim\n|   |   |-- animated.gif\n|   |   |-- fluidsim.py\n|   |   |-- init_smoke.png\n|   |   |-- peace.png\n|   |   |-- skull.png\n|   |   |-- surprise.gif\n|   |   |-- wing.png\n|   |   `-- wing.py\n|   |-- gaussian_process.png\n|   |-- gaussian_process.py\n|   |-- generative_adversarial_net.py\n|   |-- gmm.png\n|   |-- gmm.py\n|   |-- gplvm.png\n|   |-- gplvm.py\n|   |-- graph.pdf\n|   |-- hmm_em.py\n|   |-- ica.py\n|   |-- logistic_regression.py\n|   |-- lstm.py\n|   |-- mixture_variational_inference.py\n|   |-- natural_gradient_black_box_svi.py\n|   |-- negative_binomial_maxlike.py\n|   |-- neural_net.py\n|   |-- neural_net_regression.py\n|   |-- ode_net.py\n|   |-- ode_net_demo.png\n|   |-- print_trace.py\n|   |-- rkhs.py\n|   |-- rnn.py\n|   |-- rosenbrock.py\n|   |-- sinusoid.png\n|   |-- sinusoid.py\n|   |-- sinusoid_taylor.png\n|   |-- tanh.png\n|   |-- tanh.py\n|   |-- vae_samples.png\n|   `-- variational_autoencoder.py\n|-- license.txt\n|-- pyproject.toml\n|-- tests\n|   |-- _test_complexity.py\n|   |-- check_examples_run.sh\n|   |-- numpy_utils.py\n|   |-- profiling.py\n|   |-- test_binary_ops.py\n|   |-- test_builtins.py\n|   |-- test_complex.py\n|   |-- test_core.py\n|   |-- test_dict.py\n|   |-- test_direct.py\n|   |-- test_fft.py\n|   |-- test_graphs.py\n|   |-- test_jacobian.py\n|   |-- test_linalg.py\n|   |-- test_list.py\n|   |-- test_logic.py\n|   |-- test_misc.py\n|   |-- test_numpy.py\n|   |-- test_performance.py\n|   |-- test_scalar_ops.py\n|   |-- test_scipy.py\n|   |-- test_systematic.py\n|   |-- test_tests.py\n|   |-- test_truediv.py\n|   |-- test_tuple.py\n|   |-- test_vspaces.py\n|   `-- test_wrappers.py\n`-- tox.ini\n\n26 directories, 147 files\nExit code: $?\n--- End Command 1 ---\n--- Command 2 ---\nCommand: for f in README.md INSTALL.md SETUP.md docs/INSTALL.md docs/SETUP.md; do if [ -f \"$f\" ]; then echo -e \"\\n=== $f ===\"; cat \"$f\"; fi; done\nExit code:\n\n=== README.md ===\n__Note (updated May 2024): Autograd is not currently maintained, and the\nauthors do not plan to respond to future issues or pull requests. Those looking\nfor a similar user experience (with powerful additional features) can consider\nusing [JAX](https://github.com/google/jax), a successor to Autograd designed by\nthe same authors.__\n\n# Autograd  [![Checks status][checks-badge]][checks-url] [![Tests status][tests-badge]][tests-url] [![Publish status][publish-badge]][publish-url] [![asv][asv-badge]](#)\n\n[publish-badge]: https://github.com/HIPS/autograd/actions/workflows/publish.yml/badge.svg\n[checks-badge]: https://github.com/HIPS/autograd/actions/workflows/check.yml/badge.svg\n[tests-badge]: https://github.com/HIPS/autograd/actions/workflows/test.yml/badge.svg\n[asv-badge]: http://img.shields.io/badge/benchmarked%20by-asv-green.svg?style=flat\n[publish-url]: https://github.com/HIPS/autograd/actions/workflows/publish.yml\n[checks-url]: https://github.com/HIPS/autograd/actions/workflows/check.yml\n[tests-url]: https://github.com/HIPS/autograd/actions/workflows/test.yml\n\nAutograd can automatically differentiate native Python and Numpy code. It can\nhandle a large subset of Python's features, including loops, ifs, recursion and\nclosures, and it can even take derivatives of derivatives of derivatives. It\nsupports reverse-mode differentiation (a.k.a. backpropagation), which means it\ncan efficiently take gradients of scalar-valued functions with respect to\narray-valued arguments, as well as forward-mode differentiation, and the two can\nbe composed arbitrarily. The main intended application of Autograd is\ngradient-based optimization. For more information, check out the\n[tutorial](docs/tutorial.md) and the [examples directory](examples/).\n\nExample use:\n\n```python\n>>> import autograd.numpy as np  # Thinly-wrapped numpy\n>>> from autograd import grad    # The only autograd function you may ever need\n>>>\n>>> def tanh(x):                 # Define a function\n...     y = np.exp(-2.0 * x)\n...     return (1.0 - y) / (1.0 + y)\n...\n>>> grad_tanh = grad(tanh)       # Obtain its gradient function\n>>> grad_tanh(1.0)               # Evaluate the gradient at x = 1.0\n0.41997434161402603\n>>> (tanh(1.0001) - tanh(0.9999)) / 0.0002  # Compare to finite differences\n0.41997434264973155\n```\n\nWe can continue to differentiate as many times as we like, and use numpy's\nvectorization of scalar-valued functions across many different input values:\n\n```python\n>>> from autograd import elementwise_grad as egrad  # for functions that vectorize over inputs\n>>> import matplotlib.pyplot as plt\n>>> x = np.linspace(-7, 7, 200)\n>>> plt.plot(x, tanh(x),\n...          x, egrad(tanh)(x),                                     # first  derivative\n...          x, egrad(egrad(tanh))(x),                              # second derivative\n...          x, egrad(egrad(egrad(tanh)))(x),                       # third  derivative\n...          x, egrad(egrad(egrad(egrad(tanh))))(x),                # fourth derivative\n...          x, egrad(egrad(egrad(egrad(egrad(tanh)))))(x),         # fifth  derivative\n...          x, egrad(egrad(egrad(egrad(egrad(egrad(tanh))))))(x))  # sixth  derivative\n>>> plt.show()\n```\n\n<img src=\"examples/tanh.png\" width=\"600\">\n\nSee the [tanh example file](examples/tanh.py) for the code.\n\n## Documentation\n\nYou can find a tutorial [here.](docs/tutorial.md)\n\n## End-to-end examples\n\n* [Simple neural net](examples/neural_net.py)\n* [Convolutional neural net](examples/convnet.py)\n* [Recurrent neural net](examples/rnn.py)\n* [LSTM](examples/lstm.py)\n* [Neural Turing Machine](https://github.com/DoctorTeeth/diffmem/blob/512aadeefd6dbafc1bdd253a64b6be192a435dc3/ntm/ntm.py)\n* [Backpropagating through a fluid simulation](examples/fluidsim/fluidsim.py)\n\n<img src=\"exa\n[truncated to 8000 characters]\n"
        },
        {
            "script": "eval \"$(pyenv init -)\"\nls -R\ncat pyproject.toml\npyenv versions\npyenv global 3.10.13\npip install -e .[dev]\n# source $(poetry env info --path)/bin/activate\npython -c 'import cellrank'",
            "output": "",
            "exit_code": 0,
            "issues_count": 44,
            "repository": "theislab/cellrank",
            "target_reward": 0.6,
            "exploration_data": "Repository exploration for theislab/cellrank:\n=== REPOSITORY EXPLORATION START ===\n--- Command 1 ---\nCommand: tree -a -L 3 --filelimit 100 || ls -R\nExit code:\n.\n|-- .editorconfig\n|-- .git\n|   |-- FETCH_HEAD\n|   |-- HEAD\n|   |-- branches\n|   |-- config\n|   |-- description\n|   |-- hooks\n|   |   |-- applypatch-msg.sample\n|   |   |-- commit-msg.sample\n|   |   |-- fsmonitor-watchman.sample\n|   |   |-- post-update.sample\n|   |   |-- pre-applypatch.sample\n|   |   |-- pre-commit.sample\n|   |   |-- pre-merge-commit.sample\n|   |   |-- pre-push.sample\n|   |   |-- pre-rebase.sample\n|   |   |-- pre-receive.sample\n|   |   |-- prepare-commit-msg.sample\n|   |   |-- push-to-checkout.sample\n|   |   `-- update.sample\n|   |-- index\n|   |-- info\n|   |   `-- exclude\n|   |-- logs\n|   |   |-- HEAD\n|   |   `-- refs\n|   |-- objects\n|   |   |-- info\n|   |   `-- pack\n|   |-- packed-refs\n|   `-- refs\n|       |-- heads\n|       |-- remotes\n|       `-- tags\n|-- .github\n|   |-- .codecov.yml\n|   |-- ISSUE_TEMPLATE\n|   |   |-- bug_report.md\n|   |   |-- feature_request.md\n|   |   `-- question.md\n|   |-- PULL_REQUEST_TEMPLATE.md\n|   `-- workflows\n|       |-- deployment.yml\n|       |-- lint.yml\n|       `-- test.yml\n|-- .gitignore\n|-- .gitmodules\n|-- .pre-commit-config.yaml\n|-- .readthedocs.yaml\n|-- CONTRIBUTING.rst\n|-- LICENSE\n|-- MANIFEST.in\n|-- README.rst\n|-- docs\n|   |-- Makefile\n|   |-- _ext\n|   |   `-- typed_returns.py\n|   |-- _static\n|   |   |-- css\n|   |   `-- img\n|   |-- _templates\n|   |   `-- autosummary\n|   |-- about\n|   |   |-- cite.rst\n|   |   |-- index.rst\n|   |   |-- team.rst\n|   |   `-- version2.rst\n|   |-- api\n|   |   |-- datasets.rst\n|   |   |-- developer.rst\n|   |   |-- estimators.rst\n|   |   |-- index.rst\n|   |   |-- kernels.rst\n|   |   |-- models.rst\n|   |   `-- plotting.rst\n|   |-- conf.py\n|   |-- contributing.rst\n|   |-- index.rst\n|   |-- installation.rst\n|   |-- make.bat\n|   |-- notebooks\n|   |-- references.bib\n|   |-- references.rst\n|   |-- release\n|   |   |-- changelog\n|   |   |-- notes-1.0.0.rst\n|   |   |-- notes-1.1.0.rst\n|   |   |-- notes-1.2.0.rst\n|   |   |-- notes-1.3.0.rst\n|   |   |-- notes-1.3.1.rst\n|   |   |-- notes-1.4.0.rst\n|   |   |-- notes-1.5.0.rst\n|   |   |-- notes-1.5.1.rst\n|   |   `-- notes-dev.rst\n|   |-- release_notes.rst\n|   |-- spelling\n|   |   |-- autosummary.txt\n|   |   `-- general.txt\n|   `-- utils.py\n|-- pyproject.toml\n|-- src\n|   `-- cellrank\n|       |-- __init__.py\n|       |-- _utils\n|       |-- datasets.py\n|       |-- estimators\n|       |-- kernels\n|       |-- logging\n|       |-- models\n|       |-- pl\n|       `-- settings\n`-- tests\n    |-- _ground_truth_adatas\n    |   |-- adata_100.h5ad\n    |   |-- adata_200.h5ad\n    |   `-- adata_50.h5ad\n    |-- _ground_truth_figures  [282 entries exceeds filelimit, not opening dir]\n    |-- _helpers.py\n    |-- conftest.py\n    |-- test_cflare.py\n    |-- test_colors.py\n    |-- test_gpcca.py\n    |-- test_kernels.py\n    |-- test_lineage.py\n    |-- test_lineage_drivers.py\n    |-- test_linear_solver.py\n    |-- test_logging.py\n    |-- test_model.py\n    |-- test_pipeline.py\n    |-- test_plotting.py\n    |-- test_random_walk.py\n    `-- test_utils.py\n\n41 directories, 92 files\n.:\nCONTRIBUTING.rst\nLICENSE\nMANIFEST.in\nREADME.rst\ndocs\npyproject.toml\nsrc\ntests\n\n./docs:\nMakefile\n_ext\n_static\n_templates\nabout\napi\nconf.py\ncontributing.rst\nindex.rst\ninstallation.rst\nmake.bat\nnotebooks\nreferences.bib\nreferences.rst\nrelease\nrelease_notes.rst\nspelling\nutils.py\n\n./docs/_ext:\ntyped_returns.py\n\n./docs/_static:\ncss\nimg\n\n./docs/_static/css:\noverride.css\n\n./docs/_static/img:\ndark_mode_logo.png\ndark_mode_overview.png\nlight_mode_logo.png\nlight_mode_overview.png\n\n./docs/_templates:\nautosummary\n\n./docs/_templates/autosummary:\nclass.rst\n\n./docs/about:\ncite.rst\nindex.rst\nteam.rst\nversion2.rst\n\n./docs/api:\ndatasets.rst\ndeveloper.rst\nestimators.rst\nindex.rst\nkernels.rst\nmodels.rst\nplotting.rst\n\n./docs/notebooks:\n\n./docs/release:\nchangelog\nnotes-1.0.0.rst\nnotes-1.1.0.rst\nnotes-1.2.0.rst\nnotes-1.3.0.rst\nnotes-1.3.1.rst\nnotes-1.4.0.rst\nnotes-1.5.0.rst\nnotes-1.5.1.rst\nnotes-dev.rst\n\n./docs/release/changelog:\n1007.bugfix.rst\n1008.misc.rst\n1019.bugfix.rst\n1020.bugfix.rst\n1029.bugfix.rst\n1034.bugfix.rst\n1035.bugfix.rst\n1040.misc.rst\n1043.bugfix.rst\n748.bugfix.rst\n750.bugfix.rst\n761.feature.rst\n764.feature.rst\n779.feature.rst\n784.bugfix.rst\n791.feature.rst\n798.misc.rst\n828.feature.rst\n835.bugfix.rst\n842.bugfix.rst\n850.misc.rst\n861.bugfix.rst\n880.doc.rst\n883.doc.rst\n885.doc.rst\n886.feature.rst\n887.bugfix.rst\n890.feature.rst\n894.misc.rst\n896.feature.rst\n901.doc.rst\n913.misc.rst\n914.misc.rst\n923.bugfix.rst\n929.bugfix.rst\n930.feature.rst\n936.bugfix.rst\n937.bugfix.rst\n938.bugfix.rst\n943.bugfix.rst\n949.bugfix.rst\n951.bugfix.rst\n954.misc.rst\n975.doc.rst\n976.doc.rst\n978.bugfix.rst\n989.bugfix.rst\ntemplate.rst\n\n./docs/spelling:\nautosummary.txt\ngeneral.txt\n\n./src:\ncellrank\n\n./src/cellrank:\n__init__.py\n_utils\ndatasets.py\nestimators\nkernels\nlogging\nmodels\npl\nsettings\n\n./src/cellrank/_utils:\n__init__.py\n_colors.py\n_docs.py\n_enum.py\n_key.py\n_lineage.py\n_linear_solver.py\n_parallelize.py\n_utils.py\n\n./src/cellrank/estimators:\n__init__.py\n_base_estimator.py\nmixins\nterminal_states\n\n./src/cellrank/estimators/mixins:\n__init__.py\n_fate_probabilities.py\n_kernel.py\n_lineage_drivers.py\n_utils.py\ndecomposition\n\n./src/cellrank/estimators/mixins/decomposition:\n__init__.py\n_eigen.py\n_schur.py\n\n./src/cellrank/estimators/terminal_states:\n__init__.py\n_cflare.py\n_gpcca.py\n_term_states_estimator.py\n\n./src/cellrank/kernels:\n__init__.py\n_base_kernel.py\n_connectivity_kernel.py\n_cytotrace_kernel.py\n_experimental_time_kernel.py\n_precomputed_kernel.py\n_pseudotime_kernel.py\n_real_time_kernel.py\n_utils.py\n_velocity_kernel.py\nmixins\nutils\n\n./src/cellrank/kernels/mixins:\n__init__.py\n_anndata.py\n_io.py\n_kernel.py\n\n./src/cellrank/kernels/utils:\n__init__.py\n_projection.py\n_pseudotime_scheme.py\n_random_walk.py\n_similarity.py\n_tmat_flow.py\n_velocity_model.py\n\n./src/cellrank/logging:\n__init__.py\n_logging.py\n\n./src/cellrank/models:\n__init__.py\n_base_model.py\n_gamr_model.py\n_pygam_model.py\n_sklearn_model.py\n_utils.py\n\n./src/cellrank/pl:\n__init__.py\n_aggregate_fate_probs.py\n_circular_projection.py\n_cluster_trends.py\n_gene_trend.py\n_heatmap.py\n_log_odds.py\n_utils.py\n\n./src/cellrank/settings:\n__init__.py\n_settings.py\n\n./tests:\n_ground_truth_adatas\n_ground_truth_figures\n_helpers.py\nconftest.py\ntest_cflare.py\ntest_colors.py\ntest_gpcca.py\ntest_kernels.py\ntest_lineage.py\ntest_lineage_drivers.py\ntest_linear_solver.py\ntest_logging.py\ntest_model.py\ntest_pipeline.py\ntest_plotting.py\ntest_random_walk.py\ntest_utils.py\n\n./tests/_ground_truth_adatas:\nadata_100.h5ad\nadata_200.h5ad\nadata_50.h5ad\n\n./tests/_ground_truth_figures:\nall_models_for_1_gene_failed.png\nall_models_for_1_gene_failed_same_plot.png\nall_models_for_1_lineage_failed.png\nbar.png\nbar_bwd.png\nbar_cluster_subset.png\nbar_cluster_subset_violin.png\nbar_lineage_subset.png\ncluster_lineage.png\ncluster_lineage_2_failed_genes.png\ncluster_lineage_bwd.png\ncluster_lineage_covariates.png\ncluster_lineage_covariates_cmap.png\ncluster_lineage_covariates_ratio.png\ncluster_lineage_data_key.png\ncluster_lineage_gene_symbols.png\ncluster_lineage_leiden.png\ncluster_lineage_no_norm.png\ncluster_lineage_random_state.png\ncluster_lineage_raw.png\ncomposition.png\ncomposition_kwargs_autopct.png\ndriver_corr.png\ndriver_corr_adjust_text.png\ndriver_corr_cmap.png\ndriver_corr_color.png\ndriver_corr_fontsize.png\ndriver_corr_gene_sets.png\ndriver_corr_gene_sets_colors.png\ndriver_corr_legend_loc.png\ndriver_corr_return_ax.png\ndriver_corr_use_raw.png\ndrivers_ascending.png\ndrivers_backward.png\ndrivers_cmap.png\ndrivers_n_genes.png\ndrivers_title_fmt.png\nfailed_only_main_diagonal.png\nfailed_only_off_diagonal.png\nfitted_cluster_fates.png\nfitted_empty_model.png\nfitted_gene_trends.png\nfitted_heatmap\nfitted_ignore_plot_smoothed_lineage.png\nfitted_model_cells_with_weights.png\nfitted_model_conf_int.png\nfitted_model_conf_int_no_conf_int_computed.png\nfitted_model_weights.png\nflow_alpha.png\nflow_cluster_ascending.png\nflow_cluster_descending.png\nflow_c\n[truncated to 8000 characters]\n"
        },
        {
            "script": "eval \"$(pyenv init -)\"\nls\ncat setup.py\npyenv versions\npyenv global 3.13.1\npip install -e .\ngit gud",
            "output": "",
            "exit_code": 0,
            "issues_count": 14,
            "repository": "benthayer/git-gud",
            "target_reward": 0.8,
            "exploration_data": "Repository exploration for benthayer/git-gud:\n=== REPOSITORY EXPLORATION START ===\n--- Command 1 ---\nCommand: tree -a -L 3 --filelimit 100 || ls -R\nExit code:\n.\n|-- .git\n|   |-- FETCH_HEAD\n|   |-- HEAD\n|   |-- branches\n|   |-- config\n|   |-- description\n|   |-- hooks\n|   |   |-- applypatch-msg.sample\n|   |   |-- commit-msg.sample\n|   |   |-- fsmonitor-watchman.sample\n|   |   |-- post-update.sample\n|   |   |-- pre-applypatch.sample\n|   |   |-- pre-commit.sample\n|   |   |-- pre-merge-commit.sample\n|   |   |-- pre-push.sample\n|   |   |-- pre-rebase.sample\n|   |   |-- pre-receive.sample\n|   |   |-- prepare-commit-msg.sample\n|   |   |-- push-to-checkout.sample\n|   |   `-- update.sample\n|   |-- index\n|   |-- info\n|   |   `-- exclude\n|   |-- logs\n|   |   |-- HEAD\n|   |   `-- refs\n|   |-- objects\n|   |   |-- info\n|   |   `-- pack\n|   |-- packed-refs\n|   `-- refs\n|       |-- heads\n|       |-- remotes\n|       `-- tags\n|-- .github\n|   `-- workflows\n|       |-- functional-tests.yml\n|       |-- generate-preview.yml\n|       |-- mirror-osai.yml\n|       |-- pythonpublish.yml\n|       `-- style.yml\n|-- .gitignore\n|-- CONTRIBUTING.md\n|-- LICENSE.md\n|-- README.md\n|-- git-gud.1\n|-- gitgud\n|   |-- __init__.py\n|   |-- __main__.py\n|   |-- conftest.py\n|   |-- hooks\n|   |   |-- __init__.py\n|   |   `-- postrewrite.py\n|   |-- skills\n|   |   |-- __init__.py\n|   |   |-- basics\n|   |   |-- extras\n|   |   |-- intro\n|   |   |-- mixedbag\n|   |   |-- newbasics\n|   |   |-- rampup\n|   |   |-- rework\n|   |   `-- rewriting\n|   |-- tests\n|   |   |-- test_commands.py\n|   |   |-- test_operator.py\n|   |   `-- test_setup.py\n|   |-- user_messages\n|   |   |-- __init__.py\n|   |   `-- stateful.py\n|   |-- util\n|   |   |-- __init__.py\n|   |   |-- level_builder.py\n|   |   |-- operations.py\n|   |   |-- parsing.py\n|   |   |-- test_levels.py\n|   |   |-- test_parsing.py\n|   |   |-- test_util.py\n|   |   `-- testing.py\n|   `-- version.txt\n|-- level_file_templates\n|   |-- __init__.py\n|   |-- details.yaml\n|   |-- explanation.txt\n|   |-- filename.txt\n|   |-- goal.txt\n|   |-- setup.spec\n|   |-- solution.txt\n|   |-- test.spec\n|   `-- test_levels.py\n|-- make_level.py\n|-- preview.gif\n|-- previewgif.sh\n`-- setup.py\n\n30 directories, 64 files\nExit code: $?\n--- End Command 1 ---\n--- Command 2 ---\nCommand: for f in README.md INSTALL.md SETUP.md docs/INSTALL.md docs/SETUP.md; do if [ -f \"$f\" ]; then echo -e \"\\n=== $f ===\"; cat \"$f\"; fi; done\nExit code:\n\n=== README.md ===\n# Git Gud\r\n\r\n![Demonstration](./preview.gif)\r\n\r\n## What is it?\r\nWelcome to Git Gud, a command line game designed to help you learn how to use the popular version control system known as Git!\r\nAs levels progress, you will know more and more about git, and eventually become a git grandmaster!\r\n\r\nIf something's missing feel free to add an issue, or if you're interested, view the [contributors file](https://github.com/benthayer/git-gud/blob/main/CONTRIBUTING.md) and add something yourself! The project is intentially structured to make it very easy to add new levels!\r\n\r\nIf you're more of a visual learner, you should start with [\"Learn Git Branching\"](https://learngitbranching.js.org), and and then give Git Gud a try. Learn Git Branching is more visual, but with Git Gud, you're actually using git to complete the levels.\r\n\r\n## How do I use it?\r\nFor install instructions, see below.\r\n\r\nOnce Git Gud is installed, typing \"git gud\" will produce output and will start telling you what to do.\r\nGit Gud is meant to be like a game, and like a game, it has levels.\r\nThe levels are divided up into skills, each of which will introduce you to a new topic in Git.\r\nIt start off, assuming you have zero knowledge, and then builds up.\r\nFor each level, it will give you a goal and will explain what's going on.\r\nIdeally, the game will teach you everything you need to know to beat it, but you're still encouraged to use other resources to learn as much as you want.\r\n\r\nThe beginning levels of the game start by getting you accustomed to the Git Gud interface, but later on, the training wheels come off, and you'll have to remember to type in the commands.\r\nIf you ever forget which commands there are, or if you want to start on a later level, you can always run \"git gud help\"\r\nThe most important commands are `git gud goal`, `git gud status`, `git gud explain` `git gud test`, and `git gud load next`.\r\nOther commands are also useful, but the output of those commands should be enough to guide you through the level.\r\n\r\nTo get started, you need to initialize Git Gud in an empty directory.\r\nOnce Git Gud is initialized, it'll have full control over that directory, and it will start adding/removing commits and files.\r\nThere will normally be multiple branches, and you'll be expected to use Git commands to solve each level.\r\nThe levels range in difficulty, and require you to do different things.\r\nSome levels are really easy and only require you to read the explanation, but others just give you a situation and you'll need to use what you've learned to solve the level.\r\n\r\n\r\n### How to install\r\nGit Gud is written in Python 3.\r\nYou'll need to have Python >=3.6 installed in your system for Git Gud to work.\r\nI prefer using [Anaconda](https://docs.anaconda.com/anaconda/install/) to make sure everything works correctly, but you can also install with pip if you now what you're doing.\r\n\r\nOnce your environment is set up with Python >=3.6, installing is simple:\r\n```\r\npip3 install git-gud\r\n```\r\nGetting started is also simple:\r\n```\r\ngit gud\r\n```\r\nGit Gud will guide you through what to do\r\n\r\nIf either of those command don't work, there are verious things you can try:\r\n - Use `pip` instead of `pip3`\r\n - Make sure your PATH variable includes Python executables\r\n - User install: `pip3 install --user git-gud`\r\n - Use Anaconda\r\nExit code: $?\n--- End Command 2 ---\n--- Command 3 ---\nCommand: find . -type f \\( -name \"*requirements*.txt\" -o -name \"setup.py\" -o -name \"pyproject.toml\" -o -name \"setup.cfg\" -o -name \"tox.ini\" \\) | while read f; do echo -e \"\\n=== $f ===\"; cat \"$f\"; done\nExit code:\n\n=== ./setup.py ===\nfrom setuptools import setup\n\n\nwith open('README.md') as readme:\n    long_description = readme.read()\n\nsetup(\n    name='git-gud',\n    version=open('gitgud/version.txt').read().strip(),\n    url='https://github.com/benthayer/git-gud/',\n    description='A command line game to learn git',\n    author='Ben Thayer',\n    author_email='ben@benthayer.com',\n    license='MIT',\n    long_description=long_description,\n    long_description_content_type='text/markdown',\n    packages=[\n        'gitgud',\n        'gitgud.util',\n        'gitgud.hooks',\n        'gitgud.skills',\n        'gitgud.user_messages',\n        'gitgud.skills.basics',\n        'gitgud.skills.extras',\n        'gitgud.skills.rampup',\n        'gitgud.skills.rework',\n        'gitgud.skills.intro',\n        'gitgud.skills.mixedbag',\n        'gitgud.skills.rewriting',\n        'gitgud.skills.newbasics',\n    ],\n    package_data={\n        'gitgud': ['version.txt', 'welcome.txt'],\n        'gitgud.skills.intro': ['_*/*'],\n        'gitgud.skills.basics': ['_*/*'],\n        'gitgud.skills.extras': ['_*/*'],\n        'gitgud.skills.rampup': ['_*/*'],\n        'gitgud.skills.rework': ['_*/*'],\n        'gitgud.skills.mixedbag': ['_*/*'],\n        'gitgud.skills.rewriting': ['_*/*'],\n        'gitgud.skills.newbasics': ['_*/*'],\n    },\n    python_requires='>=3.6',\n    install_requires=[\n        'gitpython==3.1.7',\n        'importlib_resources',\n        'pyyaml',\n    ],\n    entry_points={\n        \"console_scripts\": [\n            \"git-gud=gitgud.__main__:main\"\n        ]\n    },\n    data_files=[('man/man1', ['git-gud.1'])]\n)\nExit code: $?\n--- End Command 3 ---\n--- Command 4 ---\nCommand: find . -type f -name \"*.py\" -exec grep -l \"python_version\\|python_requires\" {} \\;\nExit code:\n./setup.py\n./make_level.py\nExit code: $?\n--- End Command 4 ---\n--- Command 5 ---\nCommand: find . -type f \\( -name \".env*\" -o -name \"*.env\" -o -name \"Dockerfile*\" \\) | while read f; do echo -e \"\\n=== $f ===\"; cat \"$f\"; done\nExit code:\nExit code: $?\n--- End Comm\n[truncated to 8000 characters]\n"
        },
        {
            "script": "eval \"$(pyenv init -)\"\nls\ncat pyproject.toml\ncat setup.py\ncat test_requirements.txt\npyenv versions\npyenv global 3.10.13\npip install -e .\npip install -r test_requirements.txt\n# source $(poetry env info --path)/bin/activate\npython -m pip install --upgrade pip",
            "output": "",
            "exit_code": 0,
            "issues_count": 0,
            "repository": "cookiecutter/cookiecutter",
            "target_reward": 0.9,
            "exploration_data": "Repository exploration for cookiecutter/cookiecutter:\n=== REPOSITORY EXPLORATION START ===\n--- Command 1 ---\nCommand: tree -a -L 3 --filelimit 100 || ls -R\nExit code:\n.\n|-- .bandit\n|-- .git\n|   |-- FETCH_HEAD\n|   |-- HEAD\n|   |-- branches\n|   |-- config\n|   |-- description\n|   |-- hooks\n|   |   |-- applypatch-msg.sample\n|   |   |-- commit-msg.sample\n|   |   |-- fsmonitor-watchman.sample\n|   |   |-- post-update.sample\n|   |   |-- pre-applypatch.sample\n|   |   |-- pre-commit.sample\n|   |   |-- pre-merge-commit.sample\n|   |   |-- pre-push.sample\n|   |   |-- pre-rebase.sample\n|   |   |-- pre-receive.sample\n|   |   |-- prepare-commit-msg.sample\n|   |   |-- push-to-checkout.sample\n|   |   `-- update.sample\n|   |-- index\n|   |-- info\n|   |   `-- exclude\n|   |-- logs\n|   |   |-- HEAD\n|   |   `-- refs\n|   |-- objects\n|   |   |-- info\n|   |   `-- pack\n|   |-- packed-refs\n|   `-- refs\n|       |-- heads\n|       |-- remotes\n|       `-- tags\n|-- .gitattributes\n|-- .github\n|   |-- ISSUE_TEMPLATE.md\n|   |-- dependabot.yml\n|   |-- release-drafter.yml\n|   `-- workflows\n|       |-- drafter.yml\n|       |-- pip-publish.yml\n|       `-- tests.yml\n|-- .gitignore\n|-- .pre-commit-config.yaml\n|-- .readthedocs.yaml\n|-- .safety-policy.yml\n|-- AUTHORS.md\n|-- CODE_OF_CONDUCT.md\n|-- CONTRIBUTING.md\n|-- HISTORY.md\n|-- LICENSE\n|-- MANIFEST.in\n|-- Makefile\n|-- README.md\n|-- __main__.py\n|-- codecov.yml\n|-- cookiecutter\n|   |-- VERSION.txt\n|   |-- __init__.py\n|   |-- __main__.py\n|   |-- cli.py\n|   |-- config.py\n|   |-- environment.py\n|   |-- exceptions.py\n|   |-- extensions.py\n|   |-- find.py\n|   |-- generate.py\n|   |-- hooks.py\n|   |-- log.py\n|   |-- main.py\n|   |-- prompt.py\n|   |-- replay.py\n|   |-- repository.py\n|   |-- utils.py\n|   |-- vcs.py\n|   `-- zipfile.py\n|-- docs\n|   |-- AUTHORS.md\n|   |-- CODE_OF_CONDUCT.md\n|   |-- CONTRIBUTING.md\n|   |-- HISTORY.md\n|   |-- README.md\n|   |-- __init__.py\n|   |-- _templates\n|   |   `-- package.rst_t\n|   |-- advanced\n|   |   |-- boolean_variables.rst\n|   |   |-- calling_from_python.rst\n|   |   |-- choice_variables.rst\n|   |   |-- copy_without_render.rst\n|   |   |-- dict_variables.rst\n|   |   |-- directories.rst\n|   |   |-- hooks.rst\n|   |   |-- human_readable_prompts.rst\n|   |   |-- index.rst\n|   |   |-- injecting_context.rst\n|   |   |-- jinja_env.rst\n|   |   |-- local_extensions.rst\n|   |   |-- nested_config_files.rst\n|   |   |-- new_line_characters.rst\n|   |   |-- private_variables.rst\n|   |   |-- replay.rst\n|   |   |-- suppressing_prompts.rst\n|   |   |-- template_extensions.rst\n|   |   |-- templates.rst\n|   |   |-- templates_in_context.rst\n|   |   `-- user_config.rst\n|   |-- case_studies.md\n|   |-- cli_options.rst\n|   |-- conf.py\n|   |-- cookiecutter.rst\n|   |-- index.rst\n|   |-- installation.rst\n|   |-- overview.rst\n|   |-- requirements.txt\n|   |-- troubleshooting.rst\n|   |-- tutorials\n|   |   |-- index.rst\n|   |   |-- tutorial1.rst\n|   |   `-- tutorial2.rst\n|   `-- usage.rst\n|-- logo\n|   |-- cookiecutter-logo-large.png\n|   |-- cookiecutter-logo.svg\n|   `-- cookiecutter_medium.png\n|-- pyproject.toml\n|-- setup.py\n|-- test_requirements.txt\n|-- tests\n|   |-- __init__.py\n|   |-- conftest.py\n|   |-- fake-nested-templates\n|   |   |-- cookiecutter.json\n|   |   |-- fake-package\n|   |   `-- fake-project\n|   |-- fake-nested-templates-old-style\n|   |   |-- cookiecutter.json\n|   |   `-- fake-package\n|   |-- fake-repo\n|   |   |-- cookiecutter.json\n|   |   `-- fake-project\n|   |-- fake-repo-bad\n|   |   `-- no-project-in-here.txt\n|   |-- fake-repo-bad-json\n|   |   |-- cookiecutter.json\n|   |   `-- {{cookiecutter.repo_name}}\n|   |-- fake-repo-dict\n|   |   |-- cookiecutter.json\n|   |   `-- {{cookiecutter.project_slug}}\n|   |-- fake-repo-dir\n|   |   `-- my-dir\n|   |-- fake-repo-pre\n|   |   |-- cookiecutter.json\n|   |   `-- {{cookiecutter.repo_name}}\n|   |-- fake-repo-pre2\n|   |   |-- cookiecutter.json\n|   |   |-- whatever.some.thing\n|   |   `-- {%{cookiecutter.repo_name}%}\n|   |-- fake-repo-replay\n|   |   |-- cookiecutter.json\n|   |   `-- {{cookiecutter.repo_name}}\n|   |-- fake-repo-tmpl\n|   |   |-- cookiecutter.json\n|   |   `-- {{cookiecutter.repo_name}}\n|   |-- fake-repo-tmpl-_cookiecutter\n|   |   |-- cookiecutter.json\n|   |   `-- {{cookiecutter.repo_name}}\n|   |-- files\n|   |   |-- bad-zip-file.zip\n|   |   |-- empty.zip\n|   |   |-- fake-repo-tmpl.zip\n|   |   |-- not-a-repo.zip\n|   |   |-- protected-fake-repo-tmpl.zip\n|   |   |-- syntax_error.txt\n|   |   |-- unicode.txt\n|   |   |-- {%\\ if\\ cookiecutter.generate_file\\ ==\\ 'y'\\ %}cheese.txt{%\\ endif\\ %}\n|   |   |-- {{cookiecutter.generate_file}}.txt\n|   |   |-- {{cookiecutter.generate_file}}_crlf_newlines.txt\n|   |   |-- {{cookiecutter.generate_file}}_lf_newlines.txt\n|   |   |-- {{cookiecutter.jsonify_file}}.txt\n|   |   `-- {{cookiecutter.random_string_file}}.txt\n|   |-- hooks-abort-render\n|   |   |-- hooks\n|   |   `-- {{cookiecutter.repo_dir}}\n|   |-- replay\n|   |   |-- conftest.py\n|   |   |-- test_dump.py\n|   |   |-- test_load.py\n|   |   `-- test_replay.py\n|   |-- repository\n|   |   |-- test_abbreviation_expansion.py\n|   |   |-- test_determine_repo_dir_clones_repo.py\n|   |   |-- test_determine_repo_dir_finds_existing_cookiecutter.py\n|   |   |-- test_determine_repo_dir_finds_subdirectories.py\n|   |   |-- test_determine_repository_should_use_local_repo.py\n|   |   |-- test_is_repo_url.py\n|   |   `-- test_repository_has_cookiecutter_json.py\n|   |-- test-config\n|   |   |-- config-expand-user.yaml\n|   |   |-- config-expand-vars.yaml\n|   |   |-- empty-config.yaml\n|   |   |-- invalid-config-w-array.yaml\n|   |   |-- invalid-config-w-multiple-docs.yaml\n|   |   |-- invalid-config.yaml\n|   |   |-- valid-config.yaml\n|   |   `-- valid-partial-config.yaml\n|   |-- test-extensions\n|   |   |-- custom-extension-post\n|   |   |-- custom-extension-pre\n|   |   |-- default\n|   |   |-- hello_extension\n|   |   |-- local_extension\n|   |   `-- unknown\n|   |-- test-generate-binaries\n|   |   `-- input{{cookiecutter.binary_test}}\n|   |-- test-generate-context\n|   |   |-- choices_template.json\n|   |   |-- invalid-syntax.json\n|   |   |-- nested_dict.json\n|   |   |-- nested_dict_additional.json\n|   |   |-- non_ascii.json\n|   |   `-- test.json\n|   |-- test-generate-copy-without-render\n|   |   `-- {{cookiecutter.repo_name}}\n|   |-- test-generate-copy-without-render-override\n|   |   `-- {{cookiecutter.repo_name}}\n|   |-- test-generate-files\n|   |   `-- input{{cookiecutter.food}}\n|   |-- test-generate-files-line-end\n|   |   |-- cookiecutter.json\n|   |   `-- {{cookiecutter.test_name}}\n|   |-- test-generate-files-nontemplated\n|   |   `-- input\n|   |-- test-generate-files-permissions\n|   |   `-- input{{cookiecutter.permissions}}\n|   |-- test-output-folder\n|   |   |-- cookiecutter.json\n|   |   `-- {{cookiecutter.test_name}}\n|   |-- test-pyhooks\n|   |   |-- cookiecutter.json\n|   |   |-- hooks\n|   |   `-- input{{cookiecutter.pyhooks}}\n|   |-- test-pyshellhooks\n|   |   |-- cookiecutter.json\n|   |   |-- hooks\n|   |   `-- input{{pyshellhooks}}\n|   |-- test-replay\n|   |   |-- cookiedozer_load.json\n|   |   |-- invalid_replay.json\n|   |   `-- valid_replay.json\n|   |-- test-shellhooks\n|   |   |-- hooks\n|   |   `-- input{{cookiecutter.shellhooks}}\n|   |-- test-shellhooks-empty\n|   |   |-- hooks\n|   |   `-- input{{cookiecutter.shellhooks}}\n|   |-- test-shellhooks-win\n|   |   |-- hooks\n|   |   `-- input{{cookiecutter.shellhooks}}\n|   |-- test-templates\n|   |   |-- extends\n|   |   |-- include\n|   |   |-- no-templates\n|   |   `-- super\n|   |-- test_abort_generate_on_hook_error.py\n|   |-- test_cli.py\n|   |-- test_cookiecutter_invocation.py\n|   |-- test_cookiecutter_local_no_input.py\n|   |-- test_cookiecutter_local_with_input.py\n|   |-- test_cookiecutter_nested_templates.py\n|   |-- test_custom_extensions_in_hooks.py\n|   |-- test_default_extensions.py\n|   |-- test_environment.py\n|   |-- test_exceptions.py\n|   |-- test_find.py\n|   |-- test_generate_context.py\n|   |-- test_generate_copy_without_render.py\n|   |-- test_generate_copy_without_render_override.py\n|   |-- test_generate_file.py\n|   |-- test_generate_files.p\n[truncated to 8000 characters]\n"
        },
        {
            "script": "# #!/bin/bash\n\n# Set the required Python version based on the repository context\nPYTHON_VERSION=\"3.13.1\"\n\n# Install the required Python version using pyenv\necho \"Installing Python $PYTHON_VERSION...\"\npyenv install -f $PYTHON_VERSION\n\n# Set the global Python version\npyenv global $PYTHON_VERSION\n\n# Create a virtual environment for the project\necho \"Creating a virtual environment...\"\npython -m venv venv\nsource venv/bin/activate\n\n# Upgrade pip to the latest version\necho \"Upgrading pip...\"\npip install --upgrade pip\n\n# Install project dependencies from pyproject.toml\necho \"Installing project dependencies from pyproject.toml...\"\npip install -e .\n\n# Install additional dependencies from tests/requirements.txt\nif [ -f \"tests/requirements.txt\" ]; then\n    echo \"Installing test dependencies from tests/requirements.txt...\"\n    pip install -r tests/requirements.txt\nfi\n\n# Install additional dependencies from docs/requirements.txt\nif [ -f \"docs/requirements.txt\" ]; then\n    echo \"Installing documentation dependencies from docs/requirements.txt...\"\n    pip install -r docs/requirements.txt\nfi\n\necho \"Python development environment setup complete.\"",
            "output": "",
            "exit_code": 0,
            "issues_count": 2,
            "repository": "jazzband/tablib",
            "target_reward": 1.0,
            "exploration_data": "Repository exploration for jazzband/tablib:\n=== REPOSITORY EXPLORATION START ===\n--- Command 1 ---\nCommand: tree -a -L 3 --filelimit 100 || ls -R\nExit code:\n.\n|-- .coveragerc\n|-- .flake8\n|-- .git\n|   |-- FETCH_HEAD\n|   |-- HEAD\n|   |-- branches\n|   |-- config\n|   |-- description\n|   |-- hooks\n|   |   |-- applypatch-msg.sample\n|   |   |-- commit-msg.sample\n|   |   |-- fsmonitor-watchman.sample\n|   |   |-- post-update.sample\n|   |   |-- pre-applypatch.sample\n|   |   |-- pre-commit.sample\n|   |   |-- pre-merge-commit.sample\n|   |   |-- pre-push.sample\n|   |   |-- pre-rebase.sample\n|   |   |-- pre-receive.sample\n|   |   |-- prepare-commit-msg.sample\n|   |   |-- push-to-checkout.sample\n|   |   `-- update.sample\n|   |-- index\n|   |-- info\n|   |   `-- exclude\n|   |-- logs\n|   |   |-- HEAD\n|   |   `-- refs\n|   |-- objects\n|   |   |-- info\n|   |   `-- pack\n|   |-- packed-refs\n|   `-- refs\n|       |-- heads\n|       |-- remotes\n|       `-- tags\n|-- .github\n|   |-- CONTRIBUTING.md\n|   |-- release.yml\n|   `-- workflows\n|       |-- docs-lint.yml\n|       |-- release.yml\n|       `-- test.yml\n|-- .gitignore\n|-- .pre-commit-config.yaml\n|-- .readthedocs.yaml\n|-- AUTHORS\n|-- CODE_OF_CONDUCT.md\n|-- HISTORY.md\n|-- LICENSE\n|-- README.md\n|-- RELEASING.md\n|-- docs\n|   |-- Makefile\n|   |-- __init__.py\n|   |-- _templates\n|   |   |-- sidebarintro.html\n|   |   `-- sidebarlogo.html\n|   |-- api.rst\n|   |-- conf.py\n|   |-- development.rst\n|   |-- formats.rst\n|   |-- index.rst\n|   |-- install.rst\n|   |-- intro.rst\n|   |-- krstyle.sty\n|   |-- requirements.txt\n|   `-- tutorial.rst\n|-- pyproject.toml\n|-- pytest.ini\n|-- src\n|   `-- tablib\n|       |-- __init__.py\n|       |-- _vendor\n|       |-- core.py\n|       |-- exceptions.py\n|       |-- formats\n|       `-- utils.py\n|-- tests\n|   |-- files\n|   |   |-- bad_dimensions.xlsx\n|   |   |-- book.ods\n|   |   |-- dates.xls\n|   |   |-- errors.xls\n|   |   |-- founders.xlsx\n|   |   |-- issue_524.yaml\n|   |   |-- ragged.ods\n|   |   |-- ragged.xlsx\n|   |   |-- unknown_value_type.ods\n|   |   `-- xlsx_cell_values.xlsx\n|   |-- requirements.txt\n|   |-- test_tablib.py\n|   |-- test_tablib_dbfpy_packages_fields.py\n|   `-- test_tablib_dbfpy_packages_utils.py\n`-- tox.ini\n\n23 directories, 72 files\nExit code: $?\n--- End Command 1 ---\n--- Command 2 ---\nCommand: for f in README.md INSTALL.md SETUP.md docs/INSTALL.md docs/SETUP.md; do if [ -f \"$f\" ]; then echo -e \"\\n=== $f ===\"; cat \"$f\"; fi; done\nExit code:\n\n=== README.md ===\n# Tablib: format-agnostic tabular dataset library\n\n[![Jazzband](https://jazzband.co/static/img/badge.svg)](https://jazzband.co/)\n[![PyPI version](https://img.shields.io/pypi/v/tablib.svg)](https://pypi.org/project/tablib/)\n[![Supported Python versions](https://img.shields.io/pypi/pyversions/tablib.svg)](https://pypi.org/project/tablib/)\n[![PyPI downloads](https://img.shields.io/pypi/dm/tablib.svg)](https://pypistats.org/packages/tablib)\n[![GitHub Actions status](https://github.com/jazzband/tablib/workflows/Test/badge.svg)](https://github.com/jazzband/tablib/actions)\n[![codecov](https://codecov.io/gh/jazzband/tablib/branch/master/graph/badge.svg)](https://codecov.io/gh/jazzband/tablib)\n[![GitHub](https://img.shields.io/github/license/jazzband/tablib.svg)](LICENSE)\n\n    _____         ______  ___________ ______\n    __  /_______ ____  /_ ___  /___(_)___  /_\n    _  __/_  __ `/__  __ \\__  / __  / __  __ \\\n    / /_  / /_/ / _  /_/ /_  /  _  /  _  /_/ /\n    \\__/  \\__,_/  /_.___/ /_/   /_/   /_.___/\n\n\nTablib is a format-agnostic tabular dataset library, written in Python.\n\nOutput formats supported:\n\n- Excel (Sets + Books)\n- JSON (Sets + Books)\n- YAML (Sets + Books)\n- Pandas DataFrames (Sets)\n- HTML (Sets)\n- Jira (Sets)\n- LaTeX (Sets)\n- TSV (Sets)\n- ODS (Sets)\n- CSV (Sets)\n- DBF (Sets)\n\nNote that tablib *purposefully* excludes XML support. It always will. (Note: This is a\njoke. Pull requests are welcome.)\n\nTablib documentation is graciously hosted on https://tablib.readthedocs.io\n\nIt is also available in the ``docs`` directory of the source distribution.\n\nMake sure to check out [Tablib on PyPI](https://pypi.org/project/tablib/)!\n\n## Contribute\n\nPlease see the [contributing guide](https://github.com/jazzband/tablib/blob/master/.github/CONTRIBUTING.md).\nExit code: $?\n--- End Command 2 ---\n--- Command 3 ---\nCommand: find . -type f \\( -name \"*requirements*.txt\" -o -name \"setup.py\" -o -name \"pyproject.toml\" -o -name \"setup.cfg\" -o -name \"tox.ini\" \\) | while read f; do echo -e \"\\n=== $f ===\"; cat \"$f\"; done\nExit code:\n\n=== ./tests/requirements.txt ===\npytest\npytest-cov\nodfpy\nopenpyxl>=2.6.0\npyyaml\ntabulate\nxlrd\nxlwt\n\n=== ./docs/requirements.txt ===\nsphinx==6.1.3\n\n=== ./tox.ini ===\n[tox]\nusedevelop = true\nminversion = 2.4\nenvlist =\n    docs\n    lint\n    py{38,39,310,311,312,313}\n\n[testenv]\ndeps =\n    -rtests/requirements.txt\ncommands_pre =\n    - {envpython} -m pip install --only-binary :all: pandas\npassenv =\n    FORCE_COLOR\ncommands =\n    pytest {posargs:tests}\n\n[testenv:docs]\ndeps =\n    sphinx\ncommands =\n    sphinx-build -b html -d {envtmpdir}/doctrees docs {envtmpdir}/html\n\n[testenv:lint]\ndeps =\n    pre-commit\n    build\n    twine\ncommands =\n    pre-commit run --all-files\n    python -m build\n    twine check dist/*\nskip_install = true\n\n=== ./pyproject.toml ===\n[build-system]\nrequires = [\"setuptools>=58\", \"setuptools_scm[toml]>=6.2\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"tablib\"\ndescription = \"Format agnostic tabular data library (XLS, JSON, YAML, CSV, etc.)\"\nreadme = \"README.md\"\nlicense = {text = \"MIT License\"}\nauthors = [\n    {name = \"Kenneth Reitz\", email = \"me@kennethreitz.org\"}\n]\nmaintainers = [\n    {name = \"Jazzband Team\", email = \"roadies@jazzband.co\"},\n    {name = \"Hugo van Kemenade\"},\n    {name = \"Claude Paroz\", email = \"claude@2xlibre.net\"},\n]\nrequires-python = \">=3.8\"\nclassifiers = [\n    \"Development Status :: 5 - Production/Stable\",\n    \"Intended Audience :: Developers\",\n    \"Natural Language :: English\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Programming Language :: Python\",\n    \"Programming Language :: Python :: 3 :: Only\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.8\",\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n    \"Programming Language :: Python :: 3.13\",\n]\ndynamic = [\"version\"]\n\n[project.optional-dependencies]\nall = [\n    \"odfpy\",\n    \"openpyxl>=2.6.0\",\n    \"pandas\",\n    \"pyyaml\",\n    \"tabulate\",\n    \"xlrd\",\n    \"xlwt\",\n]\ncli = [\"tabulate\"]\nhtml = []\nods = [\"odfpy\"]\npandas = [\"pandas\"]\nxls = [\"xlrd\", \"xlwt\"]\nxlsx = [\"openpyxl>=2.6.0\"]\nyaml = [\"pyyaml\"]\n\n[project.urls]\nhomepage = \"https://tablib.readthedocs.io\"\ndocumentation = \"https://tablib.readthedocs.io\"\nrepository = \"https://github.com/jazzband/tablib\"\nchangelog = \"https://github.com/jazzband/tablib/blob/master/HISTORY.md\"\n\n[tool.setuptools_scm]\nwrite_to = \"src/tablib/_version.py\"\n\n[tool.isort]\nprofile = \"black\"\nExit code: $?\n--- End Command 3 ---\n--- Command 4 ---\nCommand: find . -type f -name \"*.py\" -exec grep -l \"python_version\\|python_requires\" {} \\;\nExit code:\nExit code: $?\n--- End Command 4 ---\n--- Command 5 ---\nCommand: find . -type f \\( -name \".env*\" -o -name \"*.env\" -o -name \"Dockerfile*\" \\) | while read f; do echo -e \"\\n=== $f ===\"; cat \"$f\"; done\nExit code:\nExit code: $?\n--- End Command 5 ---\n=== REPOSITORY EXPLORATION END ===\n\n"
        },
        {
            "script": "eval \"$(pyenv init -)\"\nls -la\ncat pyproject.toml\npyenv versions\npyenv global 3.12.0\npip install -e .\n# source $(poetry env info --path)/bin/activate\npython --version",
            "output": "",
            "exit_code": 0,
            "issues_count": 1,
            "repository": "pytest-dev/pytest-xdist",
            "target_reward": 1.0,
            "exploration_data": "Repository exploration for pytest-dev/pytest-xdist:\n=== REPOSITORY EXPLORATION START ===\n--- Command 1 ---\nCommand: tree -a -L 3 --filelimit 100 || ls -R\nExit code:\n.\n|-- .git\n|   |-- FETCH_HEAD\n|   |-- HEAD\n|   |-- branches\n|   |-- config\n|   |-- description\n|   |-- hooks\n|   |   |-- applypatch-msg.sample\n|   |   |-- commit-msg.sample\n|   |   |-- fsmonitor-watchman.sample\n|   |   |-- post-update.sample\n|   |   |-- pre-applypatch.sample\n|   |   |-- pre-commit.sample\n|   |   |-- pre-merge-commit.sample\n|   |   |-- pre-push.sample\n|   |   |-- pre-rebase.sample\n|   |   |-- pre-receive.sample\n|   |   |-- prepare-commit-msg.sample\n|   |   |-- push-to-checkout.sample\n|   |   `-- update.sample\n|   |-- index\n|   |-- info\n|   |   `-- exclude\n|   |-- logs\n|   |   |-- HEAD\n|   |   `-- refs\n|   |-- objects\n|   |   |-- info\n|   |   `-- pack\n|   |-- packed-refs\n|   `-- refs\n|       |-- heads\n|       |-- remotes\n|       `-- tags\n|-- .github\n|   |-- PULL_REQUEST_TEMPLATE.md\n|   |-- dependabot.yml\n|   `-- workflows\n|       |-- deploy.yml\n|       `-- test.yml\n|-- .gitignore\n|-- .pre-commit-config.yaml\n|-- .readthedocs.yaml\n|-- CHANGELOG.rst\n|-- LICENSE\n|-- README.rst\n|-- RELEASING.rst\n|-- changelog\n|   |-- 1092.trivial\n|   `-- _template.rst\n|-- docs\n|   |-- .gitignore\n|   |-- changelog.rst\n|   |-- conf.py\n|   |-- crash.rst\n|   |-- distribution.rst\n|   |-- how-it-works.rst\n|   |-- how-to.rst\n|   |-- index.rst\n|   |-- known-limitations.rst\n|   |-- remote.rst\n|   |-- requirements.txt\n|   `-- subprocess.rst\n|-- example\n|   |-- boxed.txt\n|   `-- loadscope\n|       |-- epsilon\n|       |-- requirements.txt\n|       |-- test\n|       `-- tox.ini\n|-- pyproject.toml\n|-- src\n|   `-- xdist\n|       |-- __init__.py\n|       |-- _path.py\n|       |-- dsession.py\n|       |-- looponfail.py\n|       |-- newhooks.py\n|       |-- plugin.py\n|       |-- remote.py\n|       |-- report.py\n|       |-- scheduler\n|       `-- workermanage.py\n|-- testing\n|   |-- acceptance_test.py\n|   |-- conftest.py\n|   |-- test_dsession.py\n|   |-- test_looponfail.py\n|   |-- test_newhooks.py\n|   |-- test_plugin.py\n|   |-- test_remote.py\n|   |-- test_workermanage.py\n|   `-- util.py\n`-- tox.ini\n\n25 directories, 69 files\nExit code: $?\n--- End Command 1 ---\n--- Command 2 ---\nCommand: for f in README.md INSTALL.md SETUP.md docs/INSTALL.md docs/SETUP.md; do if [ -f \"$f\" ]; then echo -e \"\\n=== $f ===\"; cat \"$f\"; fi; done\nExit code:\nExit code: $?\n--- End Command 2 ---\n--- Command 3 ---\nCommand: find . -type f \\( -name \"*requirements*.txt\" -o -name \"setup.py\" -o -name \"pyproject.toml\" -o -name \"setup.cfg\" -o -name \"tox.ini\" \\) | while read f; do echo -e \"\\n=== $f ===\"; cat \"$f\"; done\nExit code:\n\n=== ./docs/requirements.txt ===\nsphinx\nsphinx-rtd-theme\n\n=== ./tox.ini ===\n[tox]\nenvlist =\n  linting\n  py{38,39,310,311,312}-pytestlatest\n  py310-pytestmain\n  py310-psutil\n  py310-setproctitle\nisolated_build = true\n\n[testenv]\nextras =\n  testing\n  psutil: psutil\n  setproctitle: setproctitle\ndeps =\n  pytestmin: pytest==7.0.0\n  pytestlatest: pytest\n  pytestmain: git+https://github.com/pytest-dev/pytest.git\ncommands =\n  pytest {posargs:{env:_XDIST_TOX_DEFAULT_POSARGS:}}\nsetenv =\n  _XDIST_TOX_DEFAULT_POSARGS={env:_XDIST_TOX_POSARGS_PSUTIL:}\n  psutil: _XDIST_TOX_POSARGS_PSUTIL=-k psutil\n\n[testenv:linting]\nskip_install = True\nusedevelop = True\npassenv = PRE_COMMIT_HOME\ndeps =\n  pre-commit\ncommands = pre-commit run --all-files --show-diff-on-failure\n\n[testenv:release]\nchangedir =\ndescription = do a release, required posarg of the version number\nskipsdist = True\nusedevelop = True\npassenv = *\ndeps =\n  towncrier\ncommands =\n  towncrier build --version {posargs} --yes\n\n[testenv:docs]\nusedevelop = True\ndeps =\n    sphinx\n    sphinx_rtd_theme\ncommands =\n    sphinx-build -W --keep-going -b html docs docs/_build/html {posargs:}\n\n=== ./example/loadscope/tox.ini ===\n[tox]\nenvlist = test\nsetupdir = {toxinidir}/../../\n\n[testenv:test]\nbasepython = python3\npassenv = http_proxy https_proxy\ndeps = -rrequirements.txt\nchangedir = {envtmpdir}\ncommands =\n    pytest -s -v \\\n        --doctest-modules \\\n        --junitxml=tests.xml \\\n        --dist=loadscope \\\n        --tx=8*popen \\\n        {toxinidir}/test \\\n        {toxinidir}/epsilon\n\n=== ./example/loadscope/requirements.txt ===\nipdb\npytest\n../../\n\n=== ./pyproject.toml ===\n[build-system]\nrequires = [\n  \"setuptools>=61.2\",\n  \"setuptools-scm[toml]>=6.2.3\",\n]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"pytest-xdist\"\ndescription = \"pytest xdist plugin for distributed testing, most importantly across multiple CPUs\"\nreadme = \"README.rst\"\nlicense = {file=\"LICENSE\"}\nauthors = [{name = \"holger krekel and contributors\", email = \"pytest-dev@python.org\"}, {email = \"holger@merlinux.eu\"}]\nclassifiers = [\n    \"Development Status :: 5 - Production/Stable\",\n    \"Framework :: Pytest\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Operating System :: POSIX\",\n    \"Operating System :: Microsoft :: Windows\",\n    \"Operating System :: MacOS :: MacOS X\",\n    \"Topic :: Software Development :: Testing\",\n    \"Topic :: Software Development :: Quality Assurance\",\n    \"Topic :: Utilities\",\n    \"Programming Language :: Python\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3 :: Only\",\n    \"Programming Language :: Python :: 3.8\",\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n]\nrequires-python = \">=3.8\"\ndependencies = [\n    \"execnet>=2.1\",\n    \"pytest>=7.0.0\",\n]\ndynamic = [\"version\"]\n\n[project.urls]\nHomepage = \"https://github.com/pytest-dev/pytest-xdist\"\nDocumentation = \"https://pytest-xdist.readthedocs.io/en/latest\"\nChangelog = \"https://pytest-xdist.readthedocs.io/en/latest/changelog.html\"\nSource = \"https://github.com/pytest-dev/pytest-xdist\"\nTracker = \"https://github.com/pytest-dev/pytest-xdist/issues\"\n\n[project.entry-points.pytest11]\nxdist = \"xdist.plugin\"\n\"xdist.looponfail\" = \"xdist.looponfail\"\n\n[project.optional-dependencies]\ntesting = [\"filelock\"]\npsutil = [\"psutil>=3.0\"]\nsetproctitle = [\"setproctitle\"]\n\n[tool.setuptools_scm]\nwrite_to = \"src/xdist/_version.py\"\n\n[tool.pytest.ini_options]\n# pytest-services also defines a worker_id fixture, disable\n# it so they don't conflict with each other (#611).\naddopts = \"-ra -p no:pytest-services\"\ntestpaths = [\"testing\"]\n\n[tool.ruff]\nsrc = [\"src\"]\n\n[tool.ruff.format]\ndocstring-code-format = true\n\n[tool.ruff.lint]\nselect = [\n    \"B\",        # bugbear\n    \"D\",        # pydocstyle\n    \"E\",        # pycodestyle\n    \"F\",        # pyflakes\n    \"I\",        # isort\n    \"PYI\",      # flake8-pyi\n    \"UP\",       # pyupgrade\n    \"RUF\",      # ruff\n    \"W\",        # pycodestyle\n    \"T10\",      # flake8-debugger\n    \"PIE\",      # flake8-pie\n    \"FA\",       # flake8-future-annotations\n    \"PGH\",      # pygrep-hooks\n    \"PLE\",      # pylint error\n    \"PLW\",      # pylint warning\n    \"PLR1714\",  # Consider merging multiple comparisons\n]\nignore = [\n    # bugbear ignore\n    \"B011\",     # Do not `assert False` (`python -O` removes these calls)\n    \"B028\",     # No explicit `stacklevel` keyword argument found\n    # pydocstyle ignore\n    \"D100\",     # Missing docstring in public module\n    \"D101\",     # Missing docstring in public class\n    \"D102\",     # Missing docstring in public method\n    \"D103\",     # Missing docstring in public function\n    \"D104\",     # Missing docstring in public package\n    \"D105\",     # Missing docstring in magic method\n    \"D106\",     # Missing docstring in public nested class\n    \"D107\",     # Missing docstring in `__init__`\n    \"D209\",     # Multi-line docstring closing quotes should be on a separate line\n    \"D205\",     # 1 blank line required between summary line and description\n    \"D400\",     # First line should end with a period\n    \"D401\",     # First line of docstring should be in imperative mood\n    # ruff ignore\n    \"RUF012\",   # Mutable class attributes should be annotated with `typing.ClassVar`\n    # pylint igno\n[truncated to 8000 characters]\n"
        }
    ]


def format_examples_for_prompt(examples: List[Dict[str, Any]]) -> str:
    """Format examples for inclusion in the prompt."""
    formatted_examples = []
    
    for i, example in enumerate(examples, 1):
        # Include exploration data if present
        exploration_section = ""
        if example.get('exploration_data'):
            exploration_section = f"""

Repository exploration data:
```
{'' and example['exploration_data']}
```"""
        
        formatted_examples.append(f"""**EXAMPLE {i}**:
Script:
```bash
{example['script']}
```

Output during execution:
```
{example['output']}
```

Result: exit_code={example['exit_code']}, issues_count={example['issues_count']}{exploration_section}""")
    
    return "\n\n".join(formatted_examples)


AGENTIC_ADDITIONAL = """
**AGENTIC MODE - BASH TOOL ACCESS**:
You have access to a bash command tool that executes commands in a READ-ONLY EXPLORATION environment. This is for gathering information only - the actual script will run in a separate WRITABLE environment.

**CRITICAL ENVIRONMENT DETAILS**:
- Working directory: /data/project (repository is already checked out)
- File system: READ-ONLY (for exploration only - you cannot install packages or modify files)
- User: root with full permissions
- All tools from the Dockerfile are available (pyenv, conda, pip, poetry, etc.)
- Environment variables are set exactly as in the Docker container
- **IMPORTANT**: The actual script execution happens in a separate writable environment - read-only errors in exploration don't matter

**HOW TO USE THE BASH TOOL**:
1. **Check available tools**: Use commands like `which python`, `which pip`, `which poetry`, `pyenv versions`
2. **Explore repository structure**: Use `ls -la`, `find . -name "*.toml"`, `cat pyproject.toml`
3. **Check current environment**: Use `python --version`, `pip list`, `conda list`
4. **Verify file existence**: Use `test -f filename` or `ls filename`
5. **Check environment variables**: Use `echo $PATH`, `echo $PYTHON_VERSION`

**EVALUATION STRATEGY**:
1. **First, explore the repository**: Check what files exist, what Python version is required, what dependency files are present
2. **Check current environment state**: Verify what tools and Python versions are already available
3. **Test individual commands**: Use the bash tool to test commands that don't require writing (like checking versions, examining files)
4. **Identify potential issues**: Look for missing files, incompatible versions, or configuration problems
5. **Predict final state**: Determine what the environment would look like after script execution in the writable environment

**EXAMPLE BASH TOOL USAGE**:
- `ls -la` - Check repository contents
- `cat pyproject.toml` - Examine project configuration
- `which python` - Check current Python executable
- `pyenv versions` - See available Python versions
- `test -f requirements.txt` - Check if requirements file exists
- `python --version` - Check current Python version

**IMPORTANT**: Use the bash tool to gather concrete information about the repository and environment before making your prediction. Focus on exploration and information gathering - the actual script will run in a writable environment, so read-only errors during exploration don't matter for your final prediction.
"""


def create_evaluation_prompt(script: str, repo_name: str = "unknown", is_agent: bool = False, exploration_commands: Optional[str] = None) -> str:
    """Create the evaluation prompt for the LLM judge."""
    dockerfile = load_dockerfile()
    build_script = load_build_script()
    examples = format_examples_for_prompt(get_examples())
    
    res = f"""You are an expert system administrator and Docker specialist evaluating whether a bash script will successfully install a Python development environment.

**EXECUTION CONTEXT**:
The script will be executed in a Docker container with the following base configuration:
```
{dockerfile}
```

**EXECUTION PROCESS** (from python_build.sh):
{build_script}

**IMPORTANT EVALUATION DETAILS**:
1. The script runs with `set -e` (exits on any error)
2. Repository is already at /data/project (no git clone needed)
3. Conda is initialized and available
4. Script runs as root with full permissions
5. Output directory is created with 777 permissions
6. Git safe directory is configured for /data/project
7. All imports will be checked using the Python executable that is currently ACTIVE
8. The build script counts ONLY critical import issues (reportMissingImports) using pyright
9. Exit code 0 means success, any other exit code means failure

**EVALUATION CHECKLIST**:
Common:
- Installs Python
- Installs a correct Python version
- Uses a correct Python version for subsequent environment setup
- Doesn't try to install already available tools (pip, poetry, pyenv, pipenv, etc.)
- Installs all the required system packages
- Configures the system to use a correct virtual environment (if applicable)
- Uses correct paths to configuration files
- Installs all the optional dependencies
- Uses correct dependency manager
- Uses one dependency manager (either pip or poetry, not both)

Pip:
- Creates a virtual environment
- Uses pip install command correctly

Poetry:
- Uses poetry install command correctly

{examples}

**BASELINE SCRIPT TO EVALUATE**:
```bash
{script}
```

**IMPORTANT**: This is the baseline script that sets up the Python development environment. It does NOT need to run pyright or any type checking - that will be done automatically by the build script afterward.

**REPOSITORY**: {repo_name}
"""
    if exploration_commands:
        res += f"""

**REPOSITORY EXPLORATION RESULTS**:
{exploration_commands}
"""
    res += """

**YOUR TASK**:
You must act as a world model that can simulate the exact execution of this baseline bash script in the given Docker environment. The baseline script's ONLY job is to set up the Python development environment - it does NOT need to run pyright or any type checking. Pyright will be automatically installed and run by the build script after the baseline script completes.

**REASONING PROCESS**:
1. **Step-by-step simulation**: Trace through each command in the baseline script as if you were executing it in the Docker container
2. **Environment analysis**: Consider what tools and packages are already available vs. what needs to be installed
3. **Dependency resolution**: Analyze whether all required dependencies can be found and installed
4. **Path and configuration issues**: Check for correct file paths, environment variables, and configuration
5. **Error propagation**: Consider how `set -e` affects the script execution and where failures might occur
6. **Final state assessment**: Determine what Python environment will be active when pyright runs (after the baseline script completes)
7. **Import analysis**: Predict which modules will be missing based on the final environment state after the baseline script finishes

**CRITICAL CONSIDERATIONS**:
- Be extremely thorough in your reasoning - consider edge cases, version conflicts, and subtle failure modes
- Think about the exact sequence of commands and their cumulative effects
- Consider the interaction between different tools (pyenv, conda, pip, poetry, etc.)
- Analyze whether the final Python environment will have all necessary packages installed
- Remember: An empty baseline script will succeed (exit_code=0) but result in thousands of missing imports because no packages are installed
- The baseline script's success/failure is independent of how many imports will be missing - focus on whether the script itself completes successfully
- Be certain of your prediction before providing the final answer

**RESPONSE FORMAT**:
First, provide your detailed reasoning about the script execution, considering all the nuances mentioned above. Then, after your thorough analysis, provide ONLY ONE JSON object with your final prediction:

{{"exit_code": <number>, "issues_count": <number>}}

Your JSON response must appear exactly once, at the very end of your analysis, after all your reasoning is complete.

**TASK SUMMARY**:
You are evaluating whether the provided baseline bash script will successfully set up a Python development environment in a Docker container. The baseline script's job is ONLY to set up the environment - pyright will be run automatically afterward. You must:
1. Simulate the baseline script execution step-by-step in the given Docker environment
2. Analyze potential failure points and environment interactions
3. Predict the final exit code (0 for success, 1+ for failure) - this depends ONLY on whether the baseline script completes successfully
4. Estimate the number of missing import issues that pyright will detect after the baseline script finishes
5. Provide detailed reasoning followed by a single JSON response with your predictions
""" 
    if is_agent:
        res += AGENTIC_ADDITIONAL
    return res
